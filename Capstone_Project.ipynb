{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18ac94fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the necessary dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72a0e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(r'C:\\Users\\Ladhani\\Desktop\\Ai & ml 2\\CapstoneProject\\code\\sign_mnist_train.csv')\n",
    "test_df = pd.read_csv(r'C:\\Users\\Ladhani\\Desktop\\Ai & ml 2\\CapstoneProject\\code\\sign_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17dc1db3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     13     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08c395a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27455, 785), (7172, 785))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f60a9b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0f156de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " label       0\n",
      "pixel1      0\n",
      "pixel2      0\n",
      "pixel3      0\n",
      "pixel4      0\n",
      "           ..\n",
      "pixel780    0\n",
      "pixel781    0\n",
      "pixel782    0\n",
      "pixel783    0\n",
      "pixel784    0\n",
      "Length: 785, dtype: int64\n",
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values:\\n\", train_df.isnull().sum())\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"Duplicate rows:\", train_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3124e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,labels):\n",
    "    images = images.values.reshape(-1,28,28,1)\n",
    "    unique_labels = labels.unique()\n",
    "    fig,ax = plt.subplots(2,5)\n",
    "    fig.set_size_inches(10, 5)\n",
    "    k =0\n",
    "    for i in range(2):\n",
    "        for j in range(5):\n",
    "            ax[i,j].imshow(images[k],cmap='gray')\n",
    "            ax[i,j].set_title(str(unique_labels[labels[k]]))\n",
    "            k = k+1;\n",
    "#     plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b1510a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA94AAAHMCAYAAAAj7HCSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAACC9klEQVR4nO3de3iV5b3n/284RQIhHEISkDOCiBQU8FArilaoWHWsPdt27G7d01bpjONcdeu23dJOq73slHF31O66t6O92m1rx9HW6ehWqoJWxCqiIGc5BkjkFEI4JQLP74/+YLq4P1+6btd6krVW3q/r4g+/3ll5Dvf3eZ4bks9TliRJYgAAAAAAIBVdOnoDAAAAAAAoZSy8AQAAAABIEQtvAAAAAABSxMIbAAAAAIAUsfAGAAAAACBFLLwBAAAAAEgRC28AAAAAAFLEwhsAAAAAgBSx8AYAAAAAIEUsvItES0uL3XrrrTZz5kwbOHCglZWV2Zw5c4JxP/nJT+z888+36upqKy8vt2HDhtnnPvc5W758eftvNJCSF154wb7yla/YuHHjrFevXnbqqafav/t3/84WL158fMyRI0ds7ty5dvnll9uQIUOsoqLCzjjjDLvttttsz549HbfxQDvKpleAzoSeQGeV7dxnLZGesiRJko7eCPx1GzdutLPOOssmTZpkY8eOtX/5l3+xO++8M1h833nnndalSxebNGmS9evXz9avX28//OEPbevWrbZ48WI7/fTTO2YHgDz69Kc/bbt27bJPf/rTNn78eNuxY4f9+Mc/tjfeeMOeffZZu/TSS23fvn02ePBg+/znP28zZsyw6upqe/PNN+373/++DRo0yN544w3r2bNnR+8KkKpsegXoTOgJdFbZzn3WEulh4V0kjp2msrIy27lzpw0cOFAuvJWVK1fa+PHj7Tvf+Y5973vfS3lLgfRt377dampqMmr79u2z0047zSZMmGB/+MMf7MiRI7Znzx4bMGBAxrjHH3/cPv3pT9svfvEL++IXv9iemw20u2x6BehM6Al0VrnMfdYS+dGtozcA2SkrK/vAXztw4EAzM+vWjdON0nDijcPMrHfv3jZ+/Hirr683M7OuXbsGi24zs3PPPdfM7Pg4oJRl0ytAZ0JPoLPKZe6zlsgPfse7RB05csRaW1tt1apVdsMNN1hNTY39zd/8TUdvFpCa5uZme/PNN+3MM8886bgXXnjBzOyvjgNKVba9AnQW9AQ6q5PNfdYS+cdfW5SoXr16WWtrq5mZjR071ubPn29Dhw7t4K0C0nPTTTfZ/v377Y477nDHbN261W677TabOnWqXXnlle24dUDhyKZXgM6EnkBndbK5z1oi//gX7xK1cOFCe/XVV+2Xv/ylVVZW2iWXXEIaIUrWd77zHfvXf/1X++///b/blClT5Jjdu3fbFVdcYUmS2GOPPWZdunD5Q+eTTa8AnQk9gc7qr8191hIpSFB0duzYkZhZcuedd2Y1fu/evUlNTU1y9dVXp7thQAeYM2dOYmbJD37wA3fM7t27k8mTJycDBgxI3n777XbcOqBwZNMrQGdCT6Czip37rCXygx817wQqKytt3LhxtmbNmo7eFCCvvvvd79qcOXNszpw59vd///dyTFNTk1122WW2YcMGe/75523ixIntvJVAx8umV4DOhJ5AZ/VB5j5rifzgZy07gZ07d9qyZcvstNNO6+hNAfLmv/7X/2pz5syxb3/723bnnXfKMccW3evXr7fnnnvOzj777HbeSqDjZdMrQGdCT6Cz+qBzn7VEfvAv3kXkmWeesf3791tLS4uZma1YscIef/xxMzO74oor7P3337cZM2bYddddZ2PGjLGePXvamjVr7B//8R+ttbWVmwtKxo9//GP7h3/4B7v88svt4x//uC1atCjj/59//vl28OBB+9jHPmZLliyxe++91w4fPpwxbuDAgTZ69Oj23nSgXWXTK0BnQk+gs8pm7jc3N7OWSFFZkiRJR28EsjNixAjbtGmT/H8bNmywQYMG2ezZs+2VV16x+vp6O3TokNXV1dn06dPt9ttvt/Hjx7fzFgPpmD59ui1YsMD9/0mS2MaNG23kyJHumOuvv94eeeSRFLYOKBzZ9ArQmdAT6Kyymfutra2sJVLEwhsAAAAAgBTxO94AAAAAAKSIhTcAAAAAACli4Q0AAAAAQIpYeAMAAAAAkCIW3gAAAAAApKjg3uN99OhR27Ztm1VWVlpZWVlHbw5KWJIk1tLSYoMHD7YuXQr376DoCbQXegLIRE8AmegJIFNUTyQpuf/++5MRI0Yk5eXlyeTJk5OXXnopq6+rr69PzIw//Gm3P/X19Wm1QQZ6gj/F8oee4A9/Mv/QE/zhT+YfeoI//Mn8k01PpPIv3o899pjdfPPN9sADD9hHPvIR+9nPfmazZs2yFStW2LBhw076tZWVlWZm9rnPfc569OiR8f/69u3rjj9Rr169glp5ebkce+L3MTPr3r27HKvq3thu3cLD27VrVzlW1dXXe2MPHTokx1ZUVGT9Gd62KYXwt5xHjx7NemwiXle/f/9++8QnPuHOoXzKR0/8j//xP6xnz54Z/0+dM7WvsdTfDnufGzNv1Dnz5tKRI0eyqnm87Y2px3w/bz6qz/XGqvrhw4flWHXc2tra5NgFCxYEtZqaGvn1jz32WNH0xK9//evgGhdzbcr1GuL9K4rahpj5kY8ezsdnxMz/mLFKzPY+8cQTsv78888HNfXcYGbWp0+foKaeBQ4fPmyLFy8ump74wx/+IJ9/0hDTEzHnV31GzDUzZhu87fLmc679mo/7hNo27zm0oaEhqM2dO1eOVcdN1Y4cOWJLly4tmp74xS9+Edwn1PN1zDO3d7zVWO+e5H1Grp+b6/N5PnrYo+ZuzLrI27aY+0/M8cn2+Xbfvn12/vnnZ9UTqSy8586da1/96lfthhtuMDOze++915599ln76U9/anfffXfG2NbWVmttbT3+3y0tLWb25xvgiTdBtXA+5ZRT5Daoujc2ZuEdMzZm4Z3rRcCbSN4NuBAW3jGLOyXXh+aTbUe+5aMnevbsGdw8WHjHfS+z0l54x9zg1bXsmGLpiYqKiuAax8I7f5/hzT2lPRfe3txVxz0ff9ltVjw90atXL+vdu3fq22rGwvuvfUbMtT+thbf6xxevJ7JdeGfz//IlrftEWgtv9RmFvPCOOefefIyZB+qeEnPcC3XhfUw2xyLv/2zZ1tZmixcvtpkzZ2bUZ86caQsXLgzG33333VZVVXX8z9ChQ/O9SUCHoieATPQEkImeADLREyhFeV9479y5044cOWK1tbUZ9draWmtsbAzG33777dbc3Hz8T319fb43CehQ9ASQiZ4AMtETQCZ6AqUotVTzE/+5PUkS+U/w5eXl7u9eA6WEngAy0RNAJnoCyERPoJTkfeFdXV1tXbt2Df42avv27cHfWp1MeXl58HtcMb8zHfO7XjG/K6nqMb/n5/0uQ8zvhajfVX/22Wfl2ClTpsj6Xwul+EsxvweZ6+/8xHx9rr/L2V6vl8hXT3Tv3j34naBc96G9Q/Jifl9G7Zv39er8xvyOnvcZMb8rGDPW2w+1zd41Q22v16ujRo0KaqeffnpQO3jwoP3iF7+Qn5FP+eqJLl26BHM4rWtIrpkU+fjd85hrsZpjXvieVz9ZDsCJ1DyN2V5vrDpuI0aMkGP79+8f1Lxsl/fffz+oqZDSXH93PVv56gkl5hlH8X7XX/WE97kxc0GJ2V6vL9VneOc3recDbz9yzbfxFpzbt28Pan/5e9B/Sf3OsTr3xdYTXbt2Da6HMTlHuf5+dT5+pzjmeSjmXhXTw15dbUdTU5Mcu2rVqqDmhUNfcMEFQc27nsfkqmT79WbZXweinjuyHpmlHj162JQpU2zevHkZ9Xnz5smDCJQ6egLIRE8AmegJIBM9gVKUyo+a33LLLfalL33Jpk6dah/+8IftwQcftM2bN9vXv/71NL4dUPDoCSATPQFkoieATPQESk0qC+/PfvaztmvXLvve975nDQ0NNmHCBHv66adt+PDhaXw7oODRE0AmegLIRE8AmegJlJrUwtVuvPFGu/HGG9P6eKDo0BNAJnoCyERPAJnoCZSS1BbeuerSpUvwC/u5vvA+5pfnvc+NCSKIeTF9DLVvKkDDzKy5uVnWVehAbKBCrvIRNpTL92rvYLFcdevWzZ2XH1Q+wsNy5YV+xASxxQSYed9PBcZ48059RsxYj9pm73NV6I0XPFJZWZnV17dXaE6+qHC12K8/Ucz5yoeYuRsT2Hnw4MGg9vbbb8uxb7zxhqxPnTo1qHlzRIWVXXjhhVmP9ah9Hj16tBzbr1+/oOYF96i6quV672lv6j4REwqr5qMK3fJ4n6vmTUzQpSemh3MNSPTkI0RQiTmW3tjNmzcHNe8+sX///qCW72eOjlBWVhYcn1xDOL2vj1kjqOt8zOd6Y9XnxvSaF7bpBfj17ds3qHnhamqt8sorr8ix6jrvBWvGrONU/8Q8b+Ya1lxcKw8AAAAAAIoMC28AAAAAAFLEwhsAAAAAgBSx8AYAAAAAIEUsvAEAAAAASFHBxhV27do1SJlTqXNeEl1MWmBM4nVMumGuSdpeIp9KXt2zZ48cG5OOm1ZqdT6o7Y1JB23vpOI09OjRw3r06JFRyzX9NS35SAJW2xuTuh2bMh4z/9Vn5GPbVNK4dx04cS54X+99v507dwa11tZW+fWFSqXVxiTDe5+ppJX0rxKjvfTYvXv3BrUNGzbIsUuWLAlq69atk2PXr18v6yqBtlevXnLsgQMHgtqoUaPk2Lq6OlnPVlVVlayrtObGxkY5tqWlJaip415sqebq2SlGWm9jibn/xNzvVd3b/5g04pi31eTj3qquL176v7oneNd+lWruXefVcdu3b19QK7aeUEn/al+9e606v94cU58R8xzuUZ8b8/XePWXXrl1BbeXKlVl/rpnZBRdcENS8uavmubqvmZktX748621T+3f66afLseod8N6xzHauR13fsh4JAAAAAACisfAGAAAAACBFLLwBAAAAAEgRC28AAAAAAFJUVOFquQabeQEHKtwmH8EJuQa8VVZWyrEqLEMFYJj5ITRpBYTEyDWwJSYMoZCD47KlgqTU3PXCIGLOr/qMmK+PCffJx/YqMSFZJxuf7Wd4+9zW1hbUYkJzRowYIccuW7YsqHlBW+oz5s+fn/V2FSrVE4p3bnINXfS+two66tOnjxyrAsFU4I2Z2dNPPx3U1DwwM9uxY0dQUwFoJ6ur3vSCPNU+/+xnP5Njb7vttqDmhf+obejdu7ccO2bMmKD22muvybGqL2tra+XYYnPivFTzPCY8LKZPvOt5zDNHPsIQs6XCas38wCd1LLxgMxW46QV49ezZM6h581wFax48eFCO3bp1a1DzAhJV6FrMc2yh6tKlS1bPE2kFJcd8rjc25plKja2pqZFj1bXfW0+8++67sq5CNL2+Ur2irsVmZmvXrg1qKhjNTIeJLly4UI791re+FdS8+3O255lwNQAAAAAACgQLbwAAAAAAUsTCGwAAAACAFLHwBgAAAAAgRSy8AQAAAABIUVGlmqukvphE8ZgUzxje58Zsr0rK9FL2Wlpasv7cvn37yrqSVlJlrmna3mfkmobd3inuuerSpUtwntU5885jzPmN+dxcj6N3HmOSw9VnqMR3M500632Gl1areGNVUmx1dbUcqxKu33nnHTn2mWeeCWpTpkyRYwcOHBjU1LXBSxctVNmm1Z7s69OgErpVarGZ2c6dO4Payy+/LMe+8sorQW3Tpk1yrJeerOzfv1/WVQ96faWOpZeArnowJrXXuxZNnTo1qP3qV7/KehtUknWuyfftLdeeiLn25yrmDRPePqnzGHPOvPuBSg4309dz79rf3Nwc1NTzm5m+9nrXjNNPPz2oeUnl6jq/ZcsWOVbNf3VfjEmdLwTq7Rcxa4SYZ3l13Y15Jou5bnt2794d1LxrvLqeDx48WI717jUqwdxLNVfb5u3zBRdckPXY5cuXB7U1a9bIsfX19UFt4sSJcqzq7VxT7otr5QEAAAAAQJFh4Q0AAAAAQIpYeAMAAAAAkCIW3gAAAAAApKhgw9W6d+8e/NJ/roFpuYZLedvghc3EbK8K0Xj//ffl2M2bNwc1Fcrkfa63Hd62qSCNmOMeEzoQE7ATQ+1DWoExaenWrVtWwRsxgTUxYuZHDK9/1Pz39kEdl9igMLUfXvDOgAEDglpFRYUce/DgwaC2bds2OXbFihVBbdWqVXLshAkTgpoK3THTx2Ly5MlBTW1rIVOhOd44JebapD7Dmx9VVVVBzevd3//+90Ft4cKFcqwKYlNhT17dm6NeMJM6Pt7YmpqaoHbFFVfIsZWVlbKuxBx3FSL4qU99So5du3ZtUFu3bl1QO3r0qBtMVIhUMG0h3P/S+n5qLsQEpnn3y6amJlmvq6sLajt27JBjVZDUqFGj5NjGxsagpsLOzMwWLVoU1IYPHy7HqpDemIBRdXyKLXBQiXlWzXXtEBMC7YkJeNu4cWNQW7x4sRyrwvfUs4WZvyZR10cvoE3NMa8nxowZE9RWr14tx6r7q/dsmm1g2snqH3ScGf/iDQAAAABAqlh4AwAAAACQIhbeAAAAAACkiIU3AAAAAAApYuENAAAAAECKCjbVXIlJ9VN1L1U25nPVZ+QjrVMlT3qJlirVb9iwYXKsl3autjmbxOxi4CV2FrsuXbpEJSeeKK1U2VyT6L19Up/rpWqqujefvaR/lfx94MABOVYlRu/atUuOVankDQ0NcqxKe/74xz8ux9bW1ga1Q4cOybGqJ7zjUExUqrmaT166aS79ZOan+6rzqJJmzcw2bNgQ1FR6uZnuYZWgbqZ7wutVL+38q1/9alDz7jUqHTfmjQUxScnefqjv17t3bzn26quvDmrqGnDo0CH7wQ9+kPW2dTTVEzHX6FxTrL3vletneG+pUJ8b09fqTRJmZk8//bSsq6Tl5uZmOfa9997LetvU2wK8/lHb/NZbb8mxMW9CUPdMdU/J9U0m7U0l/ce8dUjVvecLNdbriZhkdTU/VDq3mVl5eXlQ89YCb7/9dlBTb20x8897zBs01LapNwV4vOuAqnvHUt0zvetTtteSmOdr/sUbAAAAAIAUsfAGAAAAACBFLLwBAAAAAEgRC28AAAAAAFJUsGlaXbt2DcILcg1X8375Xf3yvPcL9TFhCDHhDSpEwwsnUMEH/fr1k2P37Nkj6954JSaYRR2fmFAVjwqHiglQUduVayhYe+vWrVvQE7keW68n8nHOlJhwwpgAJhWW0aNHDznW64nGxsagpoIMzXTomhdWpnrtzDPPlGNVKJcXoBITKKeo+V8KwYQxwZEx13N1bGICZLZt2ybHqvMb038x18HTTz9d1j/zmc/I+rhx44KaF7ATsx8x11513L2vVwGHK1eulGM/8pGPBDV1LL2AxWKSa7CmN8dyDWLztksFenljVf3dd9+VY9U13gtX279/v6wvWrQoqMWEjc2fP1/WBw8eHNS8sEwVmOZtg3q29IK21LlT185iu09kG8IZM8fyMVbxniNU2LLXa2qNoAKczfS53Lx5sxzrBVWqIMI//elPcqzqtwkTJsixMfuhAt5UIJ1Z3Pon2/MZcx/mX7wBAAAAAEgRC28AAAAAAFLEwhsAAAAAgBSx8AYAAAAAIEUsvAEAAAAASFHBppp37949SGPMNX3cS0KNSSGMSUJUY71tUMmR3tiLL744qHkplQsWLJD1oUOHBrXzzjtPjo1JsIzZD5XC6aU0qs/NNfk3JgG6EHTp0iUqOTEb+Ug1j0nsVHPp4MGDcqzaVy+lsqWlJag1NzfLsSpx2sxs+/btQc1Ltp0yZUpQq62tlWPVfrS1tcmxXoJ5tp/rJdtmmyKd7/mVtmzffpEPap737dtXjt29e3dQ27Bhgxyrkpa9eZftdpnpef6lL31Jjj3jjDNkXSV6e3MsrTdaxMxJ9f1UWrSZPndLliwJal6ydKFSCc6xX5/LWO/r1bxRb2Yw0+fce4OASmB+88035dhly5YFNS+13pu7aj+8z1AJ1Q0NDXKsetuG92YOdf/wjvvAgQOD2mWXXZb15/7+978PajH3qULQpUuX4L6Q6/N5Pt5mFLMN7733XlDz+kdtb8zbKDZt2iTHjh07VtbVWwR+9rOfybFnnXVWUJs2bZocq7Zj7dq1WY8dMWKEHKvegpPrcwOp5gAAAAAAFAgW3gAAAAAApIiFNwAAAAAAKWLhDQAAAABAiqLTpV566SX70Y9+ZIsXL7aGhgZ78skn7Zprrjn+/5Mkse9+97v24IMPWlNTk5133nl2//3325lnnhn1fVRASExgWkwYQq6hbfkITlC8YA0VhvCv//qvcqwX+LR48eKgNnnyZDlWhV+pQCAzswkTJgQ1L/RDHYuYMB4vLEKd+zTDQDqyJ2K//kTe8c410MgLTGtqagpqvXv3lmPV/FdBOmY6GG348OFyrAqxMdMhSjNmzJBj+/TpE9S8fVaBcjHXAe8cqfPpBSGqz4gJRopVaD0Rs1/e8T4x7NPMn7vr168Pal4QjvqMfv36ybFqjnpBbGp7vXBCb97EhImq4+Zdo2PGxpw7FZh2zjnnyLEvvvhiUFu3bl1Q885brELrifamzrl3HVTncd++fXKsCp3y9l+FKu3YsUOO9XpCBdmOGjVKjlVzz7u+nH322UHNC4BV89TbZ3UfPe200+RYFUi6cePGoNbW1mavvfaa/IwYHdkTMde2tKgAzJiAVC8ErX///llvQ2tra1DzAiVPPfVUWVfPQx7VPyrs2Uw/13nhhCrIcOLEiVmPjXnOUlINV9u/f79NmjTJ7rvvPvn/77nnHps7d67dd9999vrrr1tdXZ3NmDFDpg4DpYCeADLRE0AmegLIRE+gM4r+F+9Zs2bZrFmz5P9LksTuvfdeu+OOO+zaa681M7Of//znVltba48++qh97WtfC76mtbU1429c9u7dG7tJQIeiJ4BM9ASQiZ4AMtET6Izy+jveGzZssMbGRps5c+bxWnl5uV188cW2cOFC+TV33323VVVVHf/j/cgBUIzoCSATPQFkoieATPQESlVeF97Hfu/3xN8rrq2tdX8n+Pbbb7fm5ubjf+rr6/O5SUCHoieATPQEkImeADLREyhV0T9qno0Tfxk9SRL3F9TLy8tlwABQSugJIBM9AWSiJ4BM9ARKTV4X3nV1dWb257+pGjRo0PH69u3b3XRtd8O6dQsSHXNNIfQSNFU9H2PVBeAvj8tfUkmGu3fvlmNViq0XNuGlE6rtWLt2rRxbUVER1FavXi3HTpo0SdZzpY6Pd9yzTU+NSZb+oPLZE9mm1cakK3qfpxJdd+7cKcdu2LAhqLW1tcmxKsHZm7uqfuDAATlWHUvvc730yosvvjioeW8WUAnmMW9CiEnv9xL51ffzPjfbuV5sPdG1a9estjkfqeYqEdmbH+p3C2N+31Bdc810IqynsrIyqNXU1MixXoKz4h3LmGOc6/XcS/5VabVjx46VY7du3RrURo8eHdRU6m++5bMnlFzvCTGp997xUmO91G715ol3331XjlV179lJ7YeaM2b+s5NKuf/sZz8rx1500UVBzXsLgfpc71o0bNiwoObdc5cvXx7UVFq0mdmiRYuCmnrDQin0RMw9WIl5W49HzT3vLQpq7u7atUuOVW8F8D5X7Yf3nOU9U6n71VlnnSXHXn311Vl9vZm+Zqg3J5npN3aoNx6Y6f1Q90tvG3IZZ5bnHzUfOXKk1dXV2bx5847X2trabMGCBXbBBRfk81sBRYGeADLRE0AmegLIRE+gVEX/i/e+ffsy/oZxw4YN9tZbb1n//v1t2LBhdvPNN9tdd91lY8aMsTFjxthdd91lFRUVdt111+V1w4FCQU8AmegJIBM9AWSiJ9AZRS+833jjDbvkkkuO//ctt9xiZmbXX3+9PfLII3brrbfawYMH7cYbbzz+wvvnnnvO/Wd8oNjRE0AmegLIRE8AmegJdEbRC+/p06ef9HcjysrKbM6cOTZnzpxctgsoGvQEkImeADLRE0AmegKdUSqp5mlRoQXeL7TH/KJ7ruFq6pf6vXpMYJoXnPDmm28GNe9vAHfs2CHrp512WlDzXtGgLF68WNY/+tGPBjUv0EfxQnPUcfcu2CqEQgVIxIQBFYIuXboEx0Edg5jQDy80R431QmjU+fXCV1TAh9erAwYMCGoq6MWjAtDMdOihmQ6h8UJGVMCHF3yl9jkmoMoLIFLnLtdwtPYIV0tbTF+rsTHz0ZsfKrxIBUaZ6RAn7zqogva8eTdmzJig5vWwF8wUc91V2xxzLYr5XO8cZRusaabDf9T59K4jhUoFDuYaLti9e3c5Vl3nve/Vv3//oNbU1CTHqiBCr39UKKwXBKr2zbu+ej71qU8FtcmTJ8ux6nnPOz5q27xgzZggNhUK6T1b7tu3L6hNmzYtqHnXvVIV8/wYM1Zdm7xrsTrn3vxQ89/7XHUt9YLYTj31VFlX9yAVAGhmdu211wY1L3hUBfd6c1cFpq1fv16OXblyZVC78MIL5dhsg0djrrF5DVcDAAAAAACZWHgDAAAAAJAiFt4AAAAAAKSIhTcAAAAAACli4Q0AAAAAQIqKKtVcpe95SXIqqdJLN1Wf66WmqmTO3r17y7Eq6c9Le1bbppJxvbqXlu4lGapkQC9ZsLa2Nqh5qZa//e1vg9p/+A//QY5V5847RyqxMyYBXYlJvi8EKq32ZK/iyIb39WqOeQn5FRUVQc1L+o9JCFYJ5up7mfnzXFEp0mZ6Pr388styrJq7H/nIR+TYbFP2PV6qprrGeSmn2fZasaWal5WVZXUsY5KEe/ToIceqRPCGhgY5ViWsqsRgMz0fvVTZGOr+E3t+c30bhHeNjqGu015PxLzlQZ3nvn37BjX1xpFCpnoi5pypOeI9tyiDBg2SdfUZXk+o65h3bVPn0XuWUens3j3wW9/6lqxPnTo1qHnPQ+pYxlyLYsZ6+6HeeOMdy7PPPjuoqTT5zpb0H7NGyPbrzfQ9POaa6b3RQqWae9ugksq99YSXal5dXR3Uhg4dKseq+6h3HVBz2ks1V/vs3Ue9tzRkK9f7YnGtPAAAAAAAKDIsvAEAAAAASBELbwAAAAAAUsTCGwAAAACAFBVsuFq2YQgqnMAsLohNqaqqkvXRo0cHNe+X/VeuXBnUvIAqFcbjBQCMGDEiqKlgATM/9GPDhg1BrampSY6dPHlyUFOBHWZma9asCWpemJUK4IoJlvDCItRn5BqGUAi6dOmSUyCcOi5eqIUKwtmyZUvWY73+UdvgBaO99957Qc2bd+q41NXVybFewJTaDm8+evsX8/1ypYJHcg0nLLaeUNQ+eH2jwle8OaY+17u+qvAhL9BIbVtMEKgXNKaCwrzj4J13VfdCnGKOu+LtR7bfy6t7zwjqPKtrTrEFSWV7n4jpCe+cDxw4MKuvN9PPF95Y9TyzceNGOVbdf/r06SPHqjDEj3/843LshRdeKOsqeCrmGu/dU2KefWKu0yqQVAWmmZkNGTIkqKnzlms4VXvLNoQz5jzGXIPyEeSrnpdV8LGZ2bp164Ka93yv9tm75nn3MLVGUHPJzKy5uTmoec+hqh4z1gu+VtsWcz5zxb94AwAAAACQIhbeAAAAAACkiIU3AAAAAAApYuENAAAAAECKWHgDAAAAAJCigk01z1Y+0k3V2PLycjlWJR+rJFQzs6VLlwa1RYsWybErVqwIaipB3cxs2rRpQU0l2J5s21QSaEz6uJdGqtIue/bsKcfGpAXGpOtmmyCZj6TJ9qSSOWOOoUpg9tJJe/ToEdQGDRokx6o0Ym9+qHOmUlfNzPbv3x/UNm/eLMcqXoqnZ/369UHNmyNnnnlmUPMSP5WY85Zrer/3GTEpuoVKvf3CG6eouauSms10aqr3Ngn1lgovAV2dh5hz7l231XXXuwfGyEfKa8xbJtQ1w3sTgjpu3n1C3ePVOSqFVHN1bL3+V9cx7w0RipeYrc6Zeg4x02+K8ea5qntvj1H3sE9+8pNyrNevqodinkNj5rl3jrw5rah7uffmBnXcVEJ8Pq4jHU3dE9JKKo95m4Q3Vh1z79lJ3cO8ty+pfj333HPl2HPOOUfWVbq6mndm+tlQ3S/NzPbu3RvUvL5Unzt48GA5dsCAAbKuqHmi+i9qPmQ9EgAAAAAARGPhDQAAAABAilh4AwAAAACQIhbeAAAAAACkiIU3AAAAAAApKthoQpXgrNLlYpLkvMTCbFJxj1HJeVu2bJFjV69eHdRWrVolx6oE9E2bNsmxM2bMyGq7zPwkUJVqqdLLzXSaonfcR4wYEdS84xvzuSp92JNtSnAppJqrffASf1U6r5cmqVL2vTRJNZe8bVBpm/3795dj1bzxtkElc3r75qXuvvrqq0HthhtukGNVGq+XQKuSR70035hrkeoJL+1Wjc31eloIVIKz4s1H9TYI740WKvG3ublZjlVzz7sWqxRpLyFf1b058/zzzwc1de8w08nFZnHX3Zg3T6iEeO8tBKpfvbHqGHtvY1D3qtNOOy2oqbcrFJuYc1NTUxPUvLdfqPPozXN1//GSllVfeZ+rzo/aLjOzSy65JKipeWBm1tjYKOu5JnrnIw1b9XxM+r46x2a61/74xz8GNe/+VajUs5M3Lqaeq1zfhOLdq9RzlncdU73tJZLHvEnI+37qTUsNDQ1yrLo+eM+AytSpU2XdS4NXsn0jDKnmAAAAAAAUCBbeAAAAAACkiIU3AAAAAAApYuENAAAAAECKCjZcTYXmqF9ejwlMiwku8oKSVLjAKaecIscOGDAgqPXr10+OVfsxdOhQOVaFjOzcuVOO9cJ/VHjCqaeeKsfGhHJNmDAhqHkBEEo+QiyyDZKJmQ+FINsgKe/cqKAkLzxJhfXt3btXjlXz0Zt3W7duDWrjx4+XY6urq4OaF/qh+soLAvF6RQXy3H///XLsVVddFdROP/10OVaFxw0bNkyO9ULAlJjroaJC8YotXE1Rx8ALsVHnxgsOign5Ur3i3VPUtnkBMirYyQu+Utv261//Wo695ZZbZF1th7cf6vt5AaHecVNUT3jHRwViqZA5M73PKmDUO76FqqysLOhjdZ3v3bu3/Hp1v/buEypAyQtVihm7e/furGpmui+956yFCxcGtXfeeUeO9ULX1NyLuW56/aOOuzfP165dG9S8+5o6xipE0Ezfwx555JGg5oX5FqokSdzngRPHZVv3zmO2YVxm+tnau1epdYb3PKT61QtPVp/hbYN33tX+eSG2ap56va3uo17IYl1dXVC79NJL5dgY6nki17Dm4n/KAgAAAACggLHwBgAAAAAgRSy8AQAAAABIEQtvAAAAAABSxMIbAAAAAIAUFWyqeVlZWV4Srv+Sl1iovo+XQqjqXuppz549g9rAgQPlWJVy7CW/vv7660HNSxD0ktGHDx8e1Lx0dpWK6aUbDh48OKh56eHqWHpjVd07nyrRMeZ7Fapu3boFqcbqvHtJsSrV0ktw7tOnT/wG/gUvbVOleK5YsUKOVdvmpdWq/vHSL999911ZX79+fVBTbyYw073pJf++8sorQU0ltpvpZFsvYVTNaS9ZUyUYq/R7b+4Uqq5duwZ9rK5N6lpspnvCu5aq5FUv6d/rK0Vtr5duH5OcqnpQzUUz/TYKM7MhQ4YEte3bt8uxXjKtUlFREdS8e4rqtYaGBjlW7fO4cePkWHX9Vz3lPQsUqiNHjgTXDHW8Vc1MXzfVddure2PVWyNiko+9XlPzxktsV9t2zz33yLE//vGPZV3NG+8ard5C4N1b1RsAXn75ZTlWPft496qVK1cGNXUuzHSvXHPNNUHt4MGD9tRTT8nPKEW5rkW8a4iau97YmOdVNdZ7vlfXTO/5zXtbjVrXeCn76nruvYlHzVMv6X/WrFlBTSWdm+n+8c5xton2MfcJ/sUbAAAAAIAUsfAGAAAAACBFLLwBAAAAAEgRC28AAAAAAFJU0OFqJwbJxAQcqBAaL5xAfa4KxTDzA70UFdzj/bK/CjvzQqBUaMH48ePlWC/MTQV87Nq1S45VYQje5w4aNCioeectJigoJrhAnWe1DcUWrnb48OEgxEUFznhhfyqwyQtZUUEtXhiPCqzxgpJUyJUXrKHqXmDHhg0bsvpeZmZLly6VddXbKizQTB9373NVIIl3fVHz1OsTVff65A9/+ENQ+8hHPpL1dhWqo0ePBvuswqFGjhwpv16dcy+8RQXPeXNXbYPXE14YlaICcrzQHDU/vGvxz3/+c1kfO3ZsUBsxYoQcq3rF+34qoG316tVyrDqWF198sRw7ceLEoOb1T7b3lHyHvKatvLw8mBMqbMwLg1Tz37tPqOugNzbmeq7OuRdYWFVVFdS8cDV1X9u2bZsc+8wzz8j6l770paDmBb+pEEDvuW7VqlVBzevtmpqaoLZ8+XI5tn///kHtYx/7mByrwu6mTp0a1Lxz3JnEPL/GXEO8e7B6XvW2QT3reQGASsznmulgwPr6ejk2JlxNXYu859ApU6YEtZj1WkxYc673BP7FGwAAAACAFLHwBgAAAAAgRSy8AQAAAABIEQtvAAAAAABSFLXwvvvuu+2cc86xyspKq6mpsWuuuSYIREmSxObMmWODBw+2nj172vTp093QB6DY0RNAJnoCyERPAJnoCXRWURG2CxYssJtuusnOOeccO3z4sN1xxx02c+ZMW7FixfEE73vuucfmzp1rjzzyiI0dO9a+//3v24wZM2z16tVWWVmZ9ffq2rVrkOIXk1QekzioeAm0Km3TS0ft0aNH1mPVfnjJnCoZfcyYMXKsSlY30wm93j6rz/jGN76R9diYVFnv+OSagK6+Ptc5Yta+PdHQ0BAcX5W4GJNe6SWgq3nupS+rbchHMqfqHy/ZVqWae9vrJXPW1tYGNS+9dePGjVl/7mc+85mg1q9fPzlWnTsv8XPr1q1B7aWXXpJjV6xYEdTUmxC8RO8Y7dkTBw4cCOaPemODd7zVfPKOgap71yvVP978UHWVvmxmVl1dHdS89H7VP961wetBlars3XNVer+XbLtu3TpZV/72b/82qA0bNkyOVfewmHtKzLUzRnv2hLpeqJ7wUs3VNc+7lsY8R6ixXhq4OmfevUqlHHtp4OpzhwwZIsf+27/9m6yr/fOOpUrq9+4paj/OOOMMOfbtt98OauqaY2Z2ww03BDXvHKnjo8Z6Xx+jPXuirKwsqyTqfLyBJ1fe91LH3HseUvWY5HDvfundGxsbG4Pa7t275Vj1JgN17zDT+3H22WfLsaNHj5Z1paPfVBG18D7xQvTwww9bTU2NLV682C666CJLksTuvfdeu+OOO+zaa681sz+/pqS2ttYeffRR+9rXvpa/LQcKAD0BZKIngEz0BJCJnkBnldNf4xz7W4pj7wncsGGDNTY22syZM4+PKS8vt4svvtgWLlwoP6O1tdX27t2b8QcoVvQEkImeADLRE0AmegKdxQdeeCdJYrfccotdeOGFNmHCBDP7fz9ucOKPbNbW1sofRTD78+95VFVVHf8zdOjQD7pJQIeiJ4BM9ASQiZ4AMtET6Ew+8MJ79uzZtnTpUvvVr34V/L8Tf34+SRL3Z+pvv/12a25uPv7H+50woNDRE0AmegLIRE8AmegJdCZRv+N9zDe/+U176qmn7KWXXsoIpjgW+tXY2GiDBg06Xt++fbsMLjL784+OlJeXB/UjR44EgRWq2bwgAjXWa1YVFpOP8AgVuOEFYKgwKhWIYqZDc7zgHi9YRgV8eD+W86UvfSmonXbaaXKskmswmpk+d0mSZP391OfmM2ChPXri0KFDWR1LLyBIhZGoQBczHVamArrMdGjHe++9J8eqXvP+VloF9W3ZskWOVSEc3lzyjs/kyZOD2jXXXCPHVlVVBbXBgwfLseq4L126VI5VgYrbtm2TY1977bWg5vXlueeeG9RUyIkXovRBtEdPdOnSJegJFbzlXStUWIwXIKOOjTc25v6hrv19+/aVY1W/ej2sAqa8MB6P2o/NmzfLsSogR/WJmdkVV1wR1FTYn/cZ3vFV59m7Dnj1NLVHT/zDP/xDEET24Q9/OBg3bdo0+bnqOcCb52rueWPV/PDOgfc8o6jnoZhAVy8s0Atoe+6554KaF3Co7mFemJsKn/Pud6+//npQ+9a3viXHquPj9U+pPjupsOaYoNe0qGcRL5hWPbN7vaZ6uKmpSY5V10xvPnvBgDt27Mhp27x1kdqOWbNmZT02H7KdEzFzJ2qWJUlis2fPtieeeMJeeOEFGzlyZMb/HzlypNXV1dm8efOO19ra2mzBggV2wQUXxHwroCjQE0AmegLIRE8AmegJdFZR/+J900032aOPPmq/+93vrLKy8vjvWVRVVVnPnj2trKzMbr75ZrvrrrtszJgxNmbMGLvrrrusoqLCrrvuulR2AOhI9ASQiZ4AMtETQCZ6Ap1V1ML7pz/9qZmZTZ8+PaP+8MMP25e//GUzM7v11lvt4MGDduONN1pTU5Odd9559txzz0W9cw8oFvQEkImeADLRE0AmegKdVdTC2/s9ub9UVlZmc+bMsTlz5nzQbQKKBj0BZKIngEz0BJCJnkBn1b5JAgAAAAAAdDIfKNW8PagUwlyTyr3UuZg0OpVs6yXyqbHe9xowYEBQ8/5GUO2bl1arkjLNzHbt2hXU+vXrJ8eed955Qe3E1NRjVAJmzH54CaPqc1VqvJk+xio9sr0TLHPVvXv34LirRHEvjVX1ytatW+XYJUuWBLWVK1fKsQ0NDUHNS6tVCcVegrPqKy8tXaW0qhRdM7PPfvazsj579uystsFM97aXPr527dqsP1f1q5cirZKhvR5++eWXg9qf/vSnoJaPtzm0p5EjRwZvf1CpsN4bG1T/eMnu6hrrpbyq4+il6avk45ikcu8eqHrQO7/efUIdt5qaGjn28ssvD2pnn322HKuSlmPfQpAGda/K5l/mCsmePXuC+8Tjjz8ejHv++efl159++ulBzbtGK959Vb1Fwbv/qL70njnU+Ym5jsXOL9WD6vnNLO6NOeq689Zbb8mx6k0gkyZNkmPVvcZ7zvKeqUqR2lcvUVzxrrtq/nvnXCVxe9dB9Rler6m3Anj7pp7JvIRw796ovp/3/KXSzr23GFx11VVB7cwzz5RjY8Q8+2eb4B+T9F9cKw8AAAAAAIoMC28AAAAAAFLEwhsAAAAAgBSx8AYAAAAAIEUFG67WpUuX4Bfgcw1Miwnu8gKqVCBDTDiHCjIw08EJ3i/rq+ARLxRDBRmY6TCD66+/Xo71ApuUXAPLvGCJXD9XBUvEBGkUgqNHjwbHp3///sE4b56rYDIVsGVmVl9fH9S8gBBVPzHw6hg1/71gDRUA6M1zVb/jjjvk2I9//OOy/vrrrwc1FTLnfb9TTz1VjlX7PHz4cDlWBbR5oTlDhgwJav/n//wfOXbRokVBTV1f2jPIKh9UT6hrnhc+qcZ6QWwqLKapqUmOjQkpUsFVKnDNzKy8vDyoeX25Y8eOoOaFqHn3CRWs+elPf1qOVQFT3nFQ13nvfqfq3v3Au39kKybAtVAdPXo0OO4qLMkLP/LuCYoKyfPuP6pXvOuNek9zzP1abZfH2wYvzE1th9dXKtjM67XevXsHtWuvvVaOvfTSS2VdiQp9yvK52TvHxSRmH2KuCzHHW13nvWumWpOoOWOmz6PXE+r+4/WaF26r5vT27dvlWHUd8J6HLrvssqDmrc2UXO8HaeFfvAEAAAAASBELbwAAAAAAUsTCGwAAAACAFLHwBgAAAAAgRSy8AQAAAABIUVHFOsekBaqxXsKdSq/0EgAPHjwY1LxUWfX9vARNlYrpJfE2NjYGNS/pz0tRv+mmm4LaBRdcIMemlSqbJElOn+ulUqrPVYotmfPIkSNB4qU6Xir13sxsy5YtQc1LqVTz1JvnKjHXm49qnq9bt06OVemeAwcOlGP/43/8j0HtoosukmNfeuklWVfHora2Vo5Vx8dLoq6oqAhqw4YNk2PVsVixYoUc+9prrwW1VatWybHV1dVBTfWUd44L1cGDB4MEVjVvvARn1RNbt27Neuy+ffvk2Jh0eNUrXrKtuid4/a72Y+zYsXLs5z//eVn3xitqPmV7LT6ZXJPGY96Ioba32FLN33///ayOe8wbRFQ6t5nZu+++G9S8RGR1Hcz13JjpXlOp6Gb6+ubtm3d8VA9632/ChAlB7dxzz5Vjzz777KCmrttm+jnUu+aoY+wdy2zPR7E9O73//vtZ3du8XlfHJWbuetdzdc68t7yoY+49Z6k1jTdH1fPbnj175Fivrt6g4Y1V/aPSy83M6urqgprXlzFvvcr1mp7zPSmn7w4AAAAAAE6KhTcAAAAAACli4Q0AAAAAQIpYeAMAAAAAkKKCDVfr2rVrVgEOMSEPKnDAzGzkyJFBTQXpmJk1NDQENS9gp6mpKevP3blzZ1DzQhYUL9jpP//n/yzrkyZNCmq5hteZxQVOKDGBLzGfkY+Qn0KkAizUXDIzW79+fVDbtWuXHKuCSLxzoMI5vCATFTKiAjTMzKZPnx7UbrjhBjm2vLw8qHnHYdOmTbL+4osvBrULL7xQjlWhN9u3b5dj+/TpE9RU/5mZPfPMM0Ht5ZdflmMVL9hIUaFCxRaudujQoeC6vnv37mBcfX29/HoVCuOFq6nP2Lt3rxyrQgS9+49y4MABWVf3BC8gUYU1zZ49W47t16+frKv5EBOgGSPmGh0zNtd7R7GFqyVJEhwfFeLkhXGpYxAT3rphwwY5Vj2jeOdGXce8/lH3FNXXZmZ9+/YNaqNGjZJj1XXbTD8vTps2TY4dPXp0UPOeWVVgmncdULx5quql+jzkmT9/fjCHVYCyF6qs6t58VMdWzQMz3RPq/mWm7ykxz1lev6t55wU7qzWNmX4OVZ9rpu813jOgeobznnFU3eu1mLC8bO8fXkij/MysRwIAAAAAgGgsvAEAAAAASBELbwAAAAAAUsTCGwAAAACAFLHwBgAAAAAgRQWbaq7EJNEpQ4YMkXWV4jlw4EA59t133w1qq1evlmNjEqe9BEBFpSZ+7GMfk2PPOussWVdpfzHHMibpNR8JmjHJnNmOjUnELwT79u0L0irVfFLp5WY6bVYlZZrFpeD2798/qI0fP16OnTBhQlA799xz5ViVmPv888/LsaovvcRpb+6eeuqpQW3+/PlyrEo7P+ecc+RYlaT7la98RY5V58PrYXXc33jjDTlWXV/GjBkT1Lw000Kl3ijR2NgY1Ly3STQ3Nwc1LyVcpdZ7c0wlrHrXV7UNXq+pufSFL3xBjr3yyiuDmkr/N/PTcdW90duPtNLOlVyTys30dSDXZ4xCcPTo0WCf1fn15pjije3du3dQ85KhVSK/l1Accx1Sb+a48cYb5Vh13VVvqDDz90Nts9c/6rrrva0m5hklJn1f1XN9fiu2VPTVq1cH51P1dT6uYSpRvLa2Nuuv957J1H3Nu/+otYdHJat7Cd3qXmWm57/XE+qzn3jiCTlWvU3BS5NXveLd79QbCyoqKuRY9f2GDx8e1Ly3WynFdUcBAAAAAKDIsPAGAAAAACBFLLwBAAAAAEgRC28AAAAAAFJUVOFqMVRggAoCMdO/FO8Fqlx00UVBzQvjUYFPMWEZHrVtKuzpZN+vPYPFvCCPXAPPVIhFKWtsbAzCJlRoVH19vfx6FYzhBXnU1dUFtS9/+cty7Nlnnx3UTj/9dDk2JqBKhYdt3LhRjlXhPyqMxMzs0ksvlfUDBw4ENa+3n3nmmaDmBcqtXLkyqHlhXyrgY9q0aXJsv379gtry5cvl2IkTJwY1FSoUE/JYCN5///0gxEUFyzQ0NMivV3Nk8+bNcqyap14Ak7qeq/llpsOaZs2aJcfOnDkzqKlQQDN9fY0J1DKLCyDKNXAp5nO9e0qugUmlEK7W1taWVbhazHHxxnrhaIo6j7meGzPd7+PGjZNjx44dG9R2794tx3q9osLRvLmvtjnmeSgmGDBmG7yxKszqhRdeCGrFdp845ZRT3Gt1NnINXVOhmN7neudGPaupYEEzHWCmzq23DV4ItBd6qHrCO2bqPMSEwXnXnJEjRwY17zk05vjEBBFmq7juKAAAAAAAFBkW3gAAAAAApIiFNwAAAAAAKWLhDQAAAABAigouXO1YsIAKb1C/VO+Fcalf4PdCnLyAKUV9P/WL+mY60MQL7IgJClOhBSogzszf5/YMV/PkGsbjHbNsAytaWlrysh1pO7Z9ap6psAs178z03POOoRrrzXPVP8eO7YnUPPX6T32GF+4Rcxy8/VD1mH71AmdiPldtsxfKpa5xKuTE2wa1vcdqxdITau6o/YoJhYk55zHXIG+sCm/xtlftr3ftjwlXy0fQlvp+3jyKCZKKCVdTY73jnu3nHjvmxdIT2c7TmHPuzZtcz3k+xiretVg9D3nPSF6YW8xxa8+eiDlHXk+o62Ep3Ce8+2K2cg1Xi3nG8a7n6jnAm+fq/uGdK/W53v3He6aKWeuosTHnxzsX6hnHO+5q/2LuzyqILeY+UZYUWOds2bLFhg4d2tGbgU6kvr7ehgwZ0tGb4aIn0N7oCSATPQFkoieATNn0RMEtvI8ePWrbtm2zyspKa2lpsaFDh1p9fb316dOnozctr/bu3Vuy+2ZWHPuXJIm1tLTY4MGDC/qVMfREaSiG/aMnCksxzJlcFMP+0ROFpRjmTC6KYf/oicJSDHMmF8WwfzE9UXA/at6lS5fjf1tw7J/4+/TpU7AHO1elvG9mhb9/VVVVHb0JfxU9UVoKff/oicJTyvtmVvj7R08UnlLeN7PC3z96ovCU8r6ZFf7+ZdsThftXVQAAAAAAlAAW3gAAAAAApKigF97l5eV25513Wnl5eUdvSt6V8r6Zlf7+dZRSPq6lvG9mpb9/HaWUj2sp75tZ6e9fRynl41rK+2ZW+vvXUUr5uJbyvpmV3v4VXLgaAAAAAAClpKD/xRsAAAAAgGLHwhsAAAAAgBSx8AYAAAAAIEUsvAEAAAAASBELbwAAAAAAUlTQC+8HHnjARo4caaeccopNmTLFXn755Y7epGgvvfSSXXXVVTZ48GArKyuz3/72txn/P0kSmzNnjg0ePNh69uxp06dPt+XLl3fMxka6++677ZxzzrHKykqrqamxa665xlavXp0xppj3rxDRE4WNnmh/9ERhoyfaHz1R2OiJ9kdPFLbO1BMFu/B+7LHH7Oabb7Y77rjDlixZYtOmTbNZs2bZ5s2bO3rTouzfv98mTZpk9913n/z/99xzj82dO9fuu+8+e/31162urs5mzJhhLS0t7byl8RYsWGA33XSTLVq0yObNm2eHDx+2mTNn2v79+4+PKeb9KzT0ROHPGXqifdEThT9n6In2RU8U/pyhJ9oXPVH4c6ZT9URSoM4999zk61//ekZt3LhxyW233dZBW5Q7M0uefPLJ4/999OjRpK6uLvnhD394vHbo0KGkqqoq+ad/+qcO2MLcbN++PTGzZMGCBUmSlN7+dTR6ovjmDD2RLnqi+OYMPZEueqL45gw9kS56ovjmTCn3REH+i3dbW5stXrzYZs6cmVGfOXOmLVy4sIO2Kv82bNhgjY2NGftZXl5uF198cVHuZ3Nzs5mZ9e/f38xKb/86Ej1RnHOGnkgPPVGcc4aeSA89UZxzhp5IDz1RnHOmlHuiIBfeO3futCNHjlhtbW1Gvba21hobGztoq/Lv2L6Uwn4mSWK33HKLXXjhhTZhwgQzK63962j0RPHtJz2RLnqi+PaTnkgXPVF8+0lPpIueKL79LPWe6NbRG3AyZWVlGf+dJElQKwWlsJ+zZ8+2pUuX2h//+Mfg/5XC/hWKznIsS2E/6Yn20VmOZSnsJz3RPjrLsSyF/aQn2kdnOZalsJ+l3hMF+S/e1dXV1rVr1+BvMbZv3x78bUcxq6urMzMr+v385je/aU899ZS9+OKLNmTIkOP1Utm/QkBPFNd+0hPpoyeKaz/pifTRE8W1n/RE+uiJ4trPztATBbnw7tGjh02ZMsXmzZuXUZ83b55dcMEFHbRV+Tdy5Eirq6vL2M+2tjZbsGBBUexnkiQ2e/Zse+KJJ+yFF16wkSNHZvz/Yt+/QkJPFMecoSfaDz1RHHOGnmg/9ERxzBl6ov3QE8UxZzpVT7RbjFukX//610n37t2Thx56KFmxYkVy8803J7169Uo2btzY0ZsWpaWlJVmyZEmyZMmSxMySuXPnJkuWLEk2bdqUJEmS/PCHP0yqqqqSJ554Ilm2bFny+c9/Phk0aFCyd+/eDt7yv+4b3/hGUlVVlcyfPz9paGg4/ufAgQPHxxTz/hUaeqLw5ww90b7oicKfM/RE+6InCn/O0BPti54o/DnTmXqiYBfeSZIk999/fzJ8+PCkR48eyeTJk4/HyheTF198MTGz4M/111+fJMmfI/LvvPPOpK6uLikvL08uuuiiZNmyZR270VlS+2VmycMPP3x8TDHvXyGiJwobPdH+6InCRk+0P3qisNET7Y+eKGydqSfKkiRJ8vNv5wAAAAAA4EQF+TveAAAAAACUChbeAAAAAACkiIU3AAAAAAApYuENAAAAAECKWHgDAAAAAJAiFt4AAAAAAKSIhTcAAAAAACli4Q0AAAAAQIpYeAMAAAAAkCIW3gAAAAAApIiFNwAAAAAAKWLhDQAAAABAilh4AwAAAACQIhbeAAAAAACkiIU3AAAAAAApYuENAAAAAECKWHgDAAAAAJAiFt4AAAAAAKSIhTcAAAAAACli4Q0AAAAAQIpYeAMAAAAAkCIW3gAAAAAApIiFNwAAAAAAKWLhDQAAAABAilh4AwAAAACQIhbeAAAAAACkiIU3AAAAAAApYuENAAAAAECKWHgDAAAAAJAiFt4AAAAAAKSIhTcAAAAAACli4Q0AAAAAQIpYeAMAAAAAkCIW3gAAAAAApIiFNwAAAAAAKWLhDQAAAABAilh4AwAAAACQIhbeAAAAAACkiIU3AAAAAAApYuENAAAAAECKWHgDAAAAAJAiFt4AAAAAAKSIhTcAAAAAACli4Q0AAAAAQIpYeAMAAAAAkCIW3kWipaXFbr31Vps5c6YNHDjQysrKbM6cORljjhw5YnPnzrXLL7/chgwZYhUVFXbGGWfYbbfdZnv27OmQ7QbSkk1PHPPmm2/aZZddZr1797a+ffvatddea+vXr2/fDQY6wJe//GUrKytz/yxatKijNxFITbb3iZ/85Cd2/vnnW3V1tZWXl9uwYcPsc5/7nC1fvrz9NxpIET3RsVh4F4ldu3bZgw8+aK2trXbNNdfIMQcPHrQ5c+bY8OHD7d5777Wnn37a/vZv/9YefPBB+8hHPmIHDx5s340GUpRNT5iZrVq1yqZPn25tbW32m9/8xv7n//yftmbNGps2bZrt2LGj/TYY6ADf+c537NVXXw3+VFdX26mnnmrnnHNOR28ikJps7xO7du2yWbNm2b/8y7/Yc889Z9/97ndtyZIldt5559nq1avbb4OBlNETHSxBUTh69Ghy9OjRJEmSZMeOHYmZJXfeeWfGmMOHDyc7d+4MvvZ//a//lZhZ8otf/KI9NhVoF9n0RJIkyac//emkuro6aW5uPl7buHFj0r179+TWW29tr80FCsb8+fMTM0u+/e1vd/SmAKnK9j6hrFixIjGz5Dvf+U6KWwi0L3qiY/Ev3kXi2I8FnkzXrl1twIABQf3cc881M7P6+vpUtg3oCNn0xOHDh+33v/+9ffKTn7Q+ffocrw8fPtwuueQSe/LJJ9PeTKDgPPTQQ1ZWVmZf+cpXOnpTgFRlc5/wDBw40MzMunXrls9NAjoUPdGxWHh3Ai+88IKZmZ155pkdvCVA+1q3bp0dPHjQJk6cGPy/iRMn2rvvvmuHDh3qgC0DOkZzc7M9/vjj9tGPftRGjhzZ0ZsDFJQjR45Ya2urrVq1ym644Qarqamxv/mbv+nozQI6DD2RX/yVRYnbunWr3XbbbTZ16lS78sorO3pzgHa1a9cuMzPr379/8P/69+9vSZJYU1OTDRo0qL03DegQv/rVr+zgwYP21a9+taM3BSg4vXr1stbWVjMzGzt2rM2fP9+GDh3awVsFdBx6Ir/4F+8Stnv3brviiissSRJ77LHHrEsXTjc6p5P9WNUH/ZEroBg99NBDNmDAAPvEJz7R0ZsCFJyFCxfaq6++ar/85S+tsrLSLrnkElKc0anRE/nFSqxENTU12YwZM2zr1q02b948GzVqVEdvEtDujmUeHPuX77+0e/duKysrs759+7bzVgEdY+nSpfbGG2/YF7/4RSsvL+/ozQEKzuTJk+3888+3L3zhC/biiy9akiT293//9x29WUCHoSfyix81L0FNTU122WWX2YYNG+z555+Xv98KdAajR4+2nj172rJly4L/t2zZMjvttNPslFNO6YAtA9rfQw89ZGZmN9xwQwdvCVD4Kisrbdy4cbZmzZqO3hSgINATueNfvEvMsUX3+vXr7bnnnrOzzz67ozcJ6DDdunWzq666yp544glraWk5Xt+8ebO9+OKLdu2113bg1gHtp7W11X75y1/aueeeaxMmTOjozQEK3s6dO4//BS0AeiIf+BfvIvLMM8/Y/v37jy8gVqxYYY8//riZmV1xxRVWVlZmH/vYx2zJkiV277332uHDh23RokXHv37gwIE2evToDtl2IA1/rScqKirsu9/9rp1zzjl25ZVX2m233WaHDh2yf/iHf7Dq6mr7L//lv3Tk5gPt5re//a3t3r2bf+1Gp/PX7hPvv/++zZgxw6677jobM2aM9ezZ09asWWP/+I//aK2trXbnnXd25OYDeUdPdJyyJEmSjt4IZGfEiBG2adMm+f82bNhgZnbS18Ncf/319sgjj6SxaUCH+Gs9MWLECDMzW7x4sf3d3/2dvfrqq9atWze79NJL7b/9t//GX0Sh05g5c6YtXLjQGhoarLKysqM3B2g3f+0+MWjQIJs9e7a98sorVl9fb4cOHbK6ujqbPn263X777TZ+/Ph23mIgXfREx2HhDQAAAABAivgdbwAAAAAAUsTCGwAAAACAFLHwBgAAAAAgRSy8AQAAAABIEQtvAAAAAABSxMIbAAAAAIAUdUvrgx944AH70Y9+ZA0NDXbmmWfavffea9OmTfurX3f06FHbtm2bVVZWWllZWVqbB1iSJNbS0mKDBw+2Ll3S/zsoegKFjp4AMtETQCZ6AsgU1RNJCn79618n3bt3T/75n/85WbFiRfKf/tN/Snr16pVs2rTpr35tfX19Ymb84U+7/amvr0+jDegJ/hTtH3qCP/zJ/ENP8Ic/mX/oCf7wJ/NPNj1RliRJYnl23nnn2eTJk+2nP/3p8doZZ5xh11xzjd19990n/drm5mbr27ev3XXXXXbKKadk/L8T/9vMrFs3/Y/26m+3unfvLseWl5dnPVZ9v65du2b9ud5Y9Tck3jaosd7nenV1fLy/EVT7HPO3h97f/njblq2jR49m/f1Ubd++fTZ58mTbs2ePVVVV5bQtf00+euLb3/627IETxfwNtDc25vzm+jfJ3jw4cuRITp/hfX2u884Ts70edTn2LtFq/ns9ka1Dhw7Z97///aLpic985jPBdfLRRx8Nxo8bN05+zvDhw4Oaum579Z49e8qxvXr1CmrV1dVybO/evYOad19T38+bz+oz1HaZmS1dulTWx44dG9T69Okjx6rrgLcfXj3bsfm4/2T7Gfv377ePf/zjRdMTc+fODeZJjx49gvHecVHPHd75UnPPO67Z3pdPVs9VzPUxhUdjM4u7T8Rc+72xqu6do5/97GdB7e2335af2dTUVDQ98cwzz7jXvmzker3J9b5sFvdsEDN31di0ttfM7PDhwzl9rrdt6hzl49kp2147cOCAfeELX8iqJ/L+o+ZtbW22ePFiu+222zLqM2fOtIULFwbjW1tbrbW19fh/t7S0mNmfF9kn3jxiFt4xC9mYhbeqxyy887G9aS28vZtdqS68j0n7R5Dy2RPttfCO+QwW3if/fjFiboJpLLyPKZae6N69e7CoUNvunXN1jY259qsFjZm+9nu9qxbT+Vh4q+2tqKiQY71tU+O9B9hCXXjH3ANPplh6omfPnsE8UfMxrYV3zD2lMy68YxYe7b3wVuf5ZAvJYumJXr16yb/gzBYL7/x8rlnpLrxPth0nyvvVbefOnXbkyBGrra3NqNfW1lpjY2Mw/u6777aqqqrjf4YOHZrvTQI6FD0BZKIngEz0BJCJnkApSi0V4cRVf5Ik8m8Cbr/9dmtubj7+p76+Pq1NAjoUPQFkoieATPQEkImeQCnJ+4+aV1dXW9euXYO/jdq+fXvwt1Zmf/4RKO93oU/8MaaYHyWI+R3mXMfG/A5ZzI9z5+P3bz3qs73PVcc45sf30vrR3pgfU4s5x/mWr55QP0KofmzH26+Y86B+bNr7EVwl5vf8PDE/xqh+HCgmT8H7jBj5+PFItQ0xPzKf649WtUdCrVn+eqK1tTXYD7Vf3o9Yx1wH1dj3339fjh00aFBQ837UcePGjUHN+530mHOufs/s0KFDcuzy5ctlXf2L0cCBA+VYdS06ePCgHKuuJd7x6chrd3tq72enmB8fj7mWxtyXY37lIB9irm8xP9J67EeaT9TU1BTUTj311Ky/n3ftV8fN217Va+qaY2a2bt26oKZ+vSVfv9L01+SrJ7IV8+wU82PXMc9eMffwfMh1LWCm52nMrzN41Ge0tbXl9PVePea+r85F1K8jZD0ySz169LApU6bYvHnzMurz5s2zCy64IN/fDih49ASQiZ4AMtETQCZ6AqUolb9uvOWWW+xLX/qSTZ061T784Q/bgw8+aJs3b7avf/3raXw7oODRE0AmegLIRE8AmegJlJpUFt6f/exnbdeuXfa9733PGhoabMKECfb000/LV7cAnQE9AWSiJ4BM9ASQiZ5AqUntF2xuvPFGu/HGG9P6eKDo0BNAJnoCyERPAJnoCZSS9k22iFBWVhb8snquvxCfVmBazDu0Y0JKYvbNC77KxztMY457rkFq+Qh3yvYz2itIKl9UaE6uxzutcJt8vEs8hpr/XvCVJ9fwkpiv98aq8xkTaueF8ahjob5Xru/YbG979uwJjo+6NqmAoFgxgUZnnHFGUNu8ebMcu3bt2qA2fvx4OTam3/v16xfUli5dKsd61/OampqgFjN333nnHTlWhU598pOflGOznbvwpRU2GxOYluvnpiUmRM1Mb1tlZaUc++STTwa1WbNmybGq12KCpLz9UOdjy5YtcqwKQ1RhikeOHLGtW7dmvW0dTT07xQSytmfAY64hX2b+c0Cu2xAzPib4evfu3XKsmo+DBw+WY2OeXXI9dzGhkvLrc/ruAAAAAADgpFh4AwAAAACQIhbeAAAAAACkiIU3AAAAAAApYuENAAAAAECKij7VPB/p4+oz8pFUrtIkvTQ9lQDo7ZtKOfbGxiQLemmkav/ykYia7dfHfka221tsybg9evSwHj16/NVx3lxQCZjZfN7Jvt77fjHny0vgVEnUixYtynobpk6dKse2trbKeq4J7/lINc9VbELviXJNQ21vLS0twXmLeetDzD1FXS+8462+nze/evXqJeuKOj+9e/eWY9X327lzpxzbt29fWa+oqAhqXnqsutds27ZNjlUJzt71OObtBDHJstle/9N680NaunbtGmyz2teYeR7z7BTzTBYzNh9inrM86p5ZXl4ux6q566WBDxs2LKuv98Q8W6qkcjPdl+o+XGxvv1DriZi+jkkUz3Vse8vHs4i6PnjPEureqNLLzczmz58f1GbOnCnH1tXVZf25SswaKtdj1vFnHQAAAACAEsbCGwAAAACAFLHwBgAAAAAgRSy8AQAAAABIUcGmhnTt2jX4hf2YgJCYII+YcKhcg8Y8Mb+srwI3vJAsb59VsIQXoJJW0InaNi8MLuYcZRtYkdZ+paVbt25ZBUl5Ynoi26/3PiMfoSFVVVVBbdeuXXLssmXLgtoll1wix8YEncTsh/e5KogmH5+reIEx2Qa+FFu42u7du4Pr1imnnBKM88KPYq7n6th459H7fooK+4sJvvLC1fbt2xfUmpqa5NhBgwZl/f28oLrt27cHtQMHDsixZ511VlDLRwBRGteiYrtP5BpMm+u9Nh/PEbkGn3rXsZhQWS9ATH2GF9jZ0tKS9diYMN5sv977jMGDB8ux/fr1C2qqh73ntEKlekKJWU9410F1HfPmszqOMec8NlQ55jMU7xqtvp+3DTFrD3UP27x5sxw7fPjwoHbo0CE5NiYMTu1zriHS/Is3AAAAAAApYuENAAAAAECKWHgDAAAAAJAiFt4AAAAAAKSIhTcAAAAAACkq2FRzlUIYk7aZa4pnTKqsl8jX1tYW1CorK+XYkSNHBrVt27bJsX379g1qKo3SzGzt2rWyrtICBw4cKMeqxHSVrG6WeyJqzPnMNU2+2NJqu3TpEsw1dQxjkq1P9r1OlFbqsOoTM90rXpJoQ0ND1tsQ8wYAb99iksZjjqXipevGUHNCbYM3dwpVU1NTcHx79eoVjMvHeYxJWlYJqd7cVSnsHnXN8uaHusY3NzfLsV7KsdcrSn19fVCrqanJ+vt5ac8x99w0Us3z8YaG9pTtG2FijmHMPaW93wijxnr7pvrdm3feeVfXF+8epvonZp9jrjleirS6PgwYMECOVf368ssvB7WY62Yh6NKlS3A+2/MtLzHycWxzfbaNTa1X3y8mAX3//v1Zj/V6LaZ/0jg+pJoDAAAAAFAgWHgDAAAAAJAiFt4AAAAAAKSIhTcAAAAAACkq2CQdFRCSa8BWTGBaTBCbF0RQXV0d1EaNGiXHqu0dPXq0HBtDBYGYmW3atCmoLV++XI790Ic+FNSGDRsmx6pj4YX/xBz3mLCHUg1X69GjRxDWokJv0goDigl68cSEd+UaMuJ9r5htiAkK8uQaruZtr+qrmHOvvt4LTSxU+/fvD86RCgiKuZ7HhE55Yw8ePBjUYkLyvLF9+vQJal5o23vvvZfVdpnpwE4zvX/bt2+XY1WQ59lnny3Hqm329tnbP4VwNR0kFROYFnNPyTW0LWas9wzQ0tKS9diJEycGtZ07d8qxv/vd72R96tSpQc0Lpo0JTox5HlK8fVb3Gi80UT3r/eY3v8l6GwqVCmv2xqX1/bOVj+uN+n4x8yMfx8Hr7YqKiqy/n6p7AdW5Bp7lOpZwNQAAAAAACgQLbwAAAAAAUsTCGwAAAACAFLHwBgAAAAAgRSy8AQAAAABIUcGmmisq7c9LklPJnPlIFlSpsIMGDZJj85FKnq0jR47Iukr8NDNra2sLal5a7WOPPRbUVPqlmU78HDx4sBzb2toa1LzkxVwT7ZViS6vt1q1bMK9j9iEm6T+tJOCYz1VzuqGhQY7t169fUPMS/dXcj922XJPK8zE2jYT4mM8sBIcOHQrmtTrv+ej1mM9Qx9E7tuqe4qWPl5eXBzUvPda7JygjRoyQdXUsvRToffv2BbUxY8bIsSo93zs+ufZlzBsI1DWy2HpCJTirY5DWG2Fi3gThjVXX6CFDhsixp59+elB766235NgFCxYEtcmTJ8uxXpr+H//4x6BWV1cnxzY1NQU1bz6pYxEzd71+V9/PG6veuvPFL34xqLW1tRVV2rlK+o95pox5q06uSfT5SBTP9fnE483dmOR8lfSv7mve2Ji3JMXwzlsaSffFtfIAAAAAAKDIsPAGAAAAACBFLLwBAAAAAEgRC28AAAAAAFJUsKkhZWVlWYUUxASExIR+eOETKkhNhXukSW2bF3jjBaapkCovDEEdnzfeeEOOXbFiRVA777zz5Nhp06bJuqJCKGJCSpRiC83JNiAkZr/SOgb5CLPq06dPUPNCoNauXRvUvB6uqKiQ9ZhwDhUMGLPPXkCI0p6fW2yBg+q6oAJZPDHHQAXIeHOmd+/eQW3YsGFybN++fYOaFwCozu+OHTvk2C1btgS1vXv3yrFeAKYKeVu5cqUcq8KvBg4cKMeqIDYvzEqJCWLLNTSn2Hoi2/uEN3djnp2y/XqP98yh6rt375ZjGxsbg5rXa3/605+C2qZNm+TYcePGyfqhQ4eC2vz58+VY1YOVlZVybEyAl+Kdz5jPVdumrqfF1hNKTIhgWiFo6nNjAoa9wLSYflfXXe/ZSV23zXSIoBc4qO4pzc3NcqzaDm/b1P7lGnTnfa4aGxUCmvVIAAAAAAAQjYU3AAAAAAApYuENAAAAAECKWHgDAAAAAJAiFt4AAAAAAKSoYGOds03m9JIFVcJcTIqnl3DXngnmXrLtxo0bg5qXXu4l0Kp9fv/99+VYddwGDBggx6rUw3nz5smxmzdvDmpf+MIX5NiY9O1s0wWLLZmza9euwbloz2TqmLTnmCRhL9lWpal6KZ4q7dlLSfZSoFXirbdtl112WVCLSdvs1auXHLt///6g5u1zzHFX/aO+3tuHQtWlS5dgTsWk8MZcV1T6uPe5KuW1Z8+ecqyau16Cs3p7hXfd3rVrV1A7//zz5Vhv25YuXRrU1P3HzOzaa6+VdUX1pncuVP+klcgd89xQqNSzkzq2MW958Y6BOl7eeVTPVP369ZNj1VsBvDe3/PKXvwxqo0aNkmNVyv4LL7wgx5599tlZb9uYMWPk2FWrVgU1dY030z3opUjnyrs3qrd1qOtTzNszCkFZWVkw32OuFTEJ6EpM+njMZ3jPJ2rsgQMH5FjVV/3795djvbdi/OEPfwhq3jPORRddlPXntrS0BDXvrQC5Pod6czrbNwdFrVGyHgkAAAAAAKKx8AYAAAAAIEUsvAEAAAAASBELbwAAAAAAUhQdrvbSSy/Zj370I1u8eLE1NDTYk08+addcc83x/58kiX33u9+1Bx980Jqamuy8886z+++/384888yo75NtGEJMwIEXZKAChVSQTnvbtm2brK9ZsyaoeYE3XqCC4h2f8vLyoOaFc6iAAS8MYfny5UHtV7/6lRz7la98Jah54XMqZEGFw8QEW5xMe/VEeXm5DI7KRT76Rx3bmM/1xh46dCioqfAXM7ODBw8GNS9w0Au3GTFiRFB7/PHH5djq6uqgdsEFF8ixr776alDzwhunTp0a1Lx9VmEgXk+oXlNBQ+o4fhDt2RO5hKup8+CFwlx++eVB7bXXXpNj1fH2zrma5ypUxkzPaTUXzcyuvvrqoDZo0CA5dt26dbKuwtW8QJ/TTjstqHnBb+o+4Z2jmGt3rkFouYaznUx79YQK4cyVdwxyDT31QqcWLFgQ1E499VQ5Vj2rLVq0SI798pe/HNRGjx4tx86dO1fWL7zwwqA2ffp0OVYFsS1evFiOVeGeH/rQh+TYmOu0er71jrsK1TrvvPPk93/00Uez3gZPoa0n0uJd29S58Xpq/fr1WdXM9HOEdy1+/fXXg5oXQDt27Nis6+r5wszs5ZdfDmreGkEdN29tpu6vMefYG5vt50aFeGY98v+3f/9+mzRpkt13333y/99zzz02d+5cu+++++z111+3uro6mzFjhvsgARQ7egLIRE8AmegJIBM9gc4o+l+8Z82aZbNmzZL/L0kSu/fee+2OO+44/mqRn//851ZbW2uPPvqofe1rX8tta4ECRE8AmegJIBM9AWSiJ9AZ5fV3vDds2GCNjY02c+bM47Xy8nK7+OKLbeHChfJrWltbbe/evRl/gFJBTwCZ6AkgEz0BZKInUKryuvBubGw0M7Pa2tqMem1t7fH/d6K7777bqqqqjv8ZOnRoPjcJ6FD0BJCJngAy0RNAJnoCpSqVVPMTf8k8SRL3F89vv/12a25uPv6nvr4+jU0COhQ9AWSiJ4BM9ASQiZ5AqYn+He+TqaurM7M//03VX6anbt++Pfhbq2PKy8tlanYaKYQxScv5To8+pqmpKeu6Si830wm03o/UeAnOu3fvDmrnnnuuHKs+20s1V4m3KrXXTKcTvvnmm3KsSuO98sor5VgvvbEj5LMnunTpEszhtJL+852KezIqndtMz6VJkybJsWreeAn5//7f/3tZ//CHPxzUvHTP3/zmN0Ft5MiRcqw6lg888IAcq/rV60vFu26pJN3JkycHNa9X8ymfPdG9e/dgDqtrU0xPeNe2ffv2BbXTTz9djt25c2dQ8/6VpmfPnkGtT58+cqxKfx0+fLgcq1Kg9+zZI8d627Z27dqgdvbZZ8uxapu9t2qo8+GdI3WN8q5POafNim1oj2th2s9Oah+89GRVjzmGMcfLS8jfunVrUFu1apUcqxKVVRq/mdnKlSuD2oABA+TY9957T9affvrpoDZx4kQ5Vl0fvLdtPPfcc0HNu9+pY+y9NUFRadpm+nyo1HfvuTKf8tkTZrmtH9R1wfs8VfeecVSveedG8eboP//zPwe1T3ziE3Ksum6vXr1ajlVvGzAzu+mmm4Kal5yvnqm8tzKpz/DezKHGxtz3Y+SaoJ7XrRo5cqTV1dXZvHnzjtfa2tpswYIF7qt2gFJGTwCZ6AkgEz0BZKInUKqi/8V737599u677x7/7w0bNthbb71l/fv3t2HDhtnNN99sd911l40ZM8bGjBljd911l1VUVNh1112X1w0HCgU9AWSiJ4BM9ASQiZ5AZxS98H7jjTfskksuOf7ft9xyi5mZXX/99fbII4/YrbfeagcPHrQbb7zx+Avvn3vuOfcF6UCxoyeATPQEkImeADLRE+iMohfe06dPP+nvkpSVldmcOXNszpw5uWwXUDToCSATPQFkoieATPQEOqO8hqvlU7YBIZ6YMIS0fgFf2bVrl6yr4BAvTER9hgojMTNbsmSJrJ955pneJgZiQjvUOfLOmwpyGjhwoBw7f/78oHbw4EE5dtasWUGtV69eQc0LlylU2fZErn3i1b2wjFyDkrzgERWS4oXxKM8884yse78fpkLMvD753//7fwc1LyCkd+/eQc17zcmPf/zjoHbWWWfJseeff35Qu/rqq+XYlpYWWS925eXlwVzzwtEUdQ3wgipVIKV3blTg2UsvvSTHqgCy9evXy7Fqe725pPbDC0XyQj/VNdYLV4sJtYwJMVP1mHt5rgGS7Rk0mS/ZBNPGhEPFHMOY4+U9W6iwMi94VT0nVVVVybFPPvlkUPOeAyoqKmR927ZtQe3tt9+WYy+77LKg1tbWJsfGPI/kGq7m3Z/VPV5dT2OusYVABdPmI4Q2W97xUmGoXsBpv379gtqYMWPkWBUi6AWxqV5R38vMbMuWLbKuQju9Y6bCDL1nSxVEqIJizXQ4rnfcVQ/meo5jtN+KEwAAAACAToiFNwAAAAAAKWLhDQAAAABAilh4AwAAAACQIhbeAAAAAACkqGBjnVWCc65J5V7aphp75MiRbDYzmpc8uXr16qC2Y8cOOXbRokVBzUv89JIbVSKyl7ap0qW9BE71GV5iofoML7X6nXfeCWoPPPCAHPuTn/wkqN1www1BrT1TDPOha9euwRzONV00JtU8Jgk1pi+9c67Szr1595GPfCSoee/6fOGFF2RdpWLW1dXJsTU1NbKuqOPjJfKr/ejfv78cq95koNL7zfT5UMnZ3jWgUPXs2TOYUzHpwDFj1TxVaa5meu6q9HIzs9ra2qDmvf1izZo1Qc3rNfW5KkXXzGzDhg2yrnpIfa6Zvmd6xzfmXp5ryrYn21Tj9nzrSVpi7nVqrHdcY86NOo7e9Uq9CcJLe1bPBuoNBGY6ed9L4+/Zs6esq9727jWDBw8OajFv/PDu72qbY3rCeyZTn6F6uNjeCKNSzb1xMXUl22R4M7Pm5uagpua+mZ5jXl/27ds3qG3atEmOHTt2bFDzeq21tVXW1X1p/PjxWX8/776kjvvy5cvlWFX/1Kc+JceqZyrv2SfmDT/ZKv47CgAAAAAABYyFNwAAAAAAKWLhDQAAAABAilh4AwAAAACQouJKSIigfiHeCzZTQRFeuECu3nvvPVlvamoKal64mgpF8oI1vBCM/fv3BzUvZESF6XihQuoYqzASMx1WtHnzZjl22bJlQc0LofBCHYpd9+7dg5COXIN/Yr4+JrwlJqQkJqjliiuukHUVUrJx40Y51gvyePbZZ4PaWWedJceqHuzTp48cq8IJ9+3bJ8fOmDEjqLW0tMix8+fPD2rbt2+XY1UPv/rqq0EtrVDJtPTo0SOYf7n2hHefGDp0aFBT11EzHTajvt5MX8e80Bx1ftVcNNPhe14IlBeao0KBvDBEFTgTEySVj2C0mM/INnCs2EI4sw2SSkvMc5Y3tqGhIah5vRZDzWcVgGZmtnfvXlm/5JJLgtrEiRPlWNVXXjCT2raYe2PMPI0JSi0FuYY1x36vE1VUVMixq1atCmre/T4m0FU9c2zbtk2OVfeE2JBVFQa6bt06OXbkyJFBTd2rzHRInHcsFyxYENRUELWZDl3z7oHZzpOo+1fWIwEAAAAAQDQW3gAAAAAApIiFNwAAAAAAKWLhDQAAAABAilh4AwAAAACQoqJKNVcJmF4KYUw6oRrrJdzFUJ+xZcsWOValHHvJguPGjQtqXmLhkCFDZF0lhB44cECOVYnIa9eulWPVsfTOhUoNffHFF+VYlTLvJfROnjxZ1otdWVlZkLAYk6SoeKmpuaabxqSxevtQVVUV1FauXCnHPv3000HNS973tu30008PaqtXr5Zjd+7cGdT69+8vx7711ltBzbsODBgwIKipxHYzvX9eD6teUcfSSxkuVD179swq1TzX+4GZnjfeNVq9pcJL01fzvK6uLutt8BLy1TZ4c8m7lqo3XXhvqVCpzB7V8zH38pi0dE+ppprnKuYeHtNrqu7NGfXMMXDgQDlWJSJ7fal6UPWfmf92lCuvvFLWFXWd967Rqu49h8bc92PeVJFtWnOuzx3tTSX9x/S12l/vuKpEce+NJ6NGjQpqf/zjH+VYdY323pKkekI9W3i8fVP3FDPdx6+99pocq3ri1FNPzXrbGhsbZV1di7zrS8xzThr3Cf7FGwAAAACAFLHwBgAAAAAgRSy8AQAAAABIEQtvAAAAAABSxMIbAAAAAIAUFWyqebdu3aKSkbPhJTGqukpzNTM7ePBgUOvZs6ccu27duqDmpRmrJMRBgwbJsTU1NUGturpajvW2TaV+Tps2TY5V++yl46rkRJVIbmb2f//v/w1qKi3azKxXr15BzTs+XnpwsVPJnEpMUrn3edl8nw8yVm2Dt71qjqo0fjOdTOulX27YsEHWx44dG9S8/hkxYkRQ847DO++8E9S8BHRVX7BggRyrkn/Vdpnptx6o68jRo0dlImqh6tGjR1b3CS/FVNV79Oghx6pz410Hhw0bFtQaGhrk2DPOOCOoeamyaj56SbOq7o1V13gzfd2NkY/08ZhU5ahk2SyvWzHXt0JQVlYWHAd1XLy+Ufsbc7xjzrmXOuz1oKI+w/tctR/ec8RVV10l6+o6UF9fL8eqN0d4zzjqWhRzf/aucTGJ3Nmez1LoidivP5HXE6qvNm7cKMdu3749qHnp/ep5aMWKFXKsmmOXXnqpHKvuKS0tLXKs9yyvesi7vqxatSqozZgxQ47dvHlzUFNvQzKLSzWPeXODquf69pfi6h4AAAAAAIoMC28AAAAAAFLEwhsAAAAAgBSx8AYAAAAAIEUFG66WbUDIyb7+RCrYyeMFJ3hhS0pMsMaQIUOCmhdkoAJyVDCUtw1mOszgrLPOkmNVCFpFRYUcu2PHjqD2+OOPy7EqkGTcuHFZjx01apQcq6gwhFwDEtpb165d3Xn5l2ICWfIRrhZDfa4KDTEz6927d1AbM2aMHDtx4sSgFhNkaGb25ptvBrUrr7xSjp0wYUJQU0EpZjpYZerUqXKsqv/iF7+QYwcPHhzUvLCvJUuWBLVZs2YFtba2NnvkkUfkZxSiioqKIMQlZp6r+4R3ja+srAxqXgiUCpbxwmZU6M2zzz4rxx44cCCoHT58WI5tbW0Nat491AsTVdsccyzzMVZd89ozFDKXUKZCkdb1POYems2962RjVYCmmQ6Z9KhnKu/ZyXu+eO+994KaCq800/cgL4hN3cO85ywVMOWdY/Xc650LdT5jnpuLibq2efM5JoxLXY+9461C7ry5pD7DC2JTYZlqjWGmA8w83rOT6kF1/zHTc9cL+1P7t2vXLjlWnTuvf9J4Fo6692Q9EgAAAAAARGPhDQAAAABAilh4AwAAAACQIhbeAAAAAACkiIU3AAAAAAApKvpU83ykpqp6TAKnRyV8ewmcKlnQ2waV9uwlCPbv31/Wr7/++qDmJSKrJF3Piy++mPXnjh49Oqh5Se6qPnz48Ky3KyaVslB16dIlmKsx6YwxYpJMY7ZBfa6XDN2rV6+gpnrKTKdXeomW/fr1k/W1a9cGtfvuu0+Oveqqq4LasGHD5Fg1/70U6ZdffjmoefusUslfeeUVObalpSWoXX755UHtwIEDRZVq3qNHjyCdVs2xfPSEOmfe9XXx4sVB7UMf+pAc26dPn6AWkz6uEmzNdF95886rq4R3L9lWpcrG3J+9+12ubzPxPrdU05oVlRrsHddc056946q2wXtuUdug7gfe2O7du8uxanu967b3FgJ1PVdJ595Y780248ePD2recY9Jk881qbzY3v6idOvWLTifMc+EuV6Dqqur5VjVE95bXtSbSbxnmVWrVmX1vczM+vbtG9QuvPBCOfb++++X9aeffjqoefdG9Vzm9ZoSkyYf8xaqtN78IL9Xu30nAAAAAAA6IRbeAAAAAACkiIU3AAAAAAApYuENAAAAAECKiipcLfbrTxQT3hLzvRsbG2W9qakpqJ111lly7AsvvBDUvKCxgQMHBrU9e/bIsZ/73OdkXQXvqNA2Mx3+s3HjRjl23759Qa2mpkaOVcEqXrCEOh9jx46VYzs7Lzgl1yC2mLExveaFq6nv54VwqDk2YsQIOdYLwlGBPAMGDMh67Pr16+XYj370o0Ht2muvlWNVkJoKUTPToShPPfWUHKtCHSdMmBDUVP8Wsq5du2YVzBIT8uVdg1TIkAp0MTPbu3dvUBsyZIgcq66l3ueqEDQvNEeF2HhjvYA2da/x+lVdz73jrq4PMYGmMZ8b+xkfdFwhSytIVPWEdw5UX3m9pgL8vM9V1+K6ujo5VvWlF8Tm9cSuXbuCmnrW88Z6IXHjxo0Lat4zoJqTMQF4pRCYlit1DGLC1bznLHV99K4h6t6lnrfN9L3Zew7funVrUPOeeyZPnhzUVDiomVllZaWsq/uEt9ZRdW8NpcLRtm/fLseqfvXud+p8xFwjc36WznokAAAAAACIxsIbAAAAAIAUsfAGAAAAACBFLLwBAAAAAEhR1ML77rvvtnPOOccqKyutpqbGrrnmGlu9enXGmCRJbM6cOTZ48GDr2bOnTZ8+3ZYvX57XjQYKBT0BZKIngEz0BJCJnkBnFZVqvmDBArvpppvsnHPOscOHD9sdd9xhM2fOtBUrVhxParznnnts7ty59sgjj9jYsWPt+9//vs2YMcNWr17tJuIp2aaa5yOtUyVrqpQ+z4IFC2S9f//+Qc07BqrubYNK/FRpyGZ+8qKiEgTNdCJyfX29HKuS/bx00P379wc1L7m0qqoqqE2fPl2ObU/t2RNdunQJjm9MkqJK0PT6J9ckXy9pWqU1xyQRewm01dXVQc1LJFd9aaaTaYcOHSrHXnLJJUHttNNOk2MvvPDCrL6XmU5E9VI8N2zYENS8h5JJkyYFtZi5F6M9e6Jbt27BXItJLFVzT6Vzm+lztnPnTjlW7YOXUJztdpnp9P6Ya7+6d5yMSof2Us1V4npMSrBHHYuYlPoY6uvzkWpeiM9OMW+eiOF9rkoYjnmLiZf2rK7Rai6a6be/eGO9a7S6Hntj1fXBe9uGet5Tz0ixYt7wo+7PaSXiF2JPxOyr94yjrrvec7h6nvGSuNX3U282MTMbNmxYUFu0aJEcqz7jnXfekWOvuOIKWb/88suDmnqDgJm+v65bt06OVfPRu9+psd69PNdUcyVq7sR88L/9279l/PfDDz9sNTU1tnjxYrvooossSRK799577Y477jj+upyf//znVltba48++qh97Wtfi/l2QMGjJ4BM9ASQiZ4AMtET6Kxy+qvc5uZmM/t//4K0YcMGa2xstJkzZx4fU15ebhdffLEtXLhQfkZra6vt3bs34w9QrOgJIBM9AWSiJ4BM9AQ6iw+88E6SxG655Ra78MILbcKECWb2/16CfuKPJtfW1rovSL/77rutqqrq+B/vRzuBQkdPAJnoCSATPQFkoifQmXzghffs2bNt6dKl9qtf/Sr4fyf+rHuSJO7Pv99+++3W3Nx8/I/3u8NAoaMngEz0BJCJngAy0RPoTKJ+x/uYb37zm/bUU0/ZSy+9ZEOGDDlePxbE0tjYaIMGDTpe3759uwzoMvvzj46owJejR48GgQQxISeqMb1mVWEGXgDTihUrgtratWvl2Ouuuy6oLVu2TI5V3693795yrDoO3t/seaEFihfqcCzo4i95QWwqDMQLUImhgrIK6W8z26MnFDUX8hE8pMJA8hEypCRJIuvq+3kBO2qOep/r9VXMZ4wePTqoeeFqKvTjvffek2O3bNkS1LxwNXUt8R407rjjjqCmQoW8oKEPoj16QgUOKvkI+VLnxjNy5MigduxHKU90yimnBDUviE1dS73AQTXWm88edZ2PCarzQpxiwm1iAs/U/uXj3OdLMdwnchUT6KqujWY6wM8L01LXUq8n1D7v27cv67FmOjDN+4zdu3cHtRkzZsixap+9cLWYuRvT89n2Wj7nTiH1hEddx7znWnU99+aj2lbvx+MrKiqCmne/Vp+r7klmOjz5qquukmNVuKeZnv9eCFpLS0tQ864Dar3l7bP6jMGDB8ux3lonWzHrSyWqe5IksdmzZ9sTTzxhL7zwQnAiR44caXV1dTZv3rzjtba2NluwYIFdcMEFMd8KKAr0BJCJngAy0RNAJnoCnVXUv3jfdNNN9uijj9rvfvc7q6ysPP57FlVVVdazZ08rKyuzm2++2e666y4bM2aMjRkzxu666y6rqKiQ//oLFDt6AshETwCZ6AkgEz2Bzipq4f3Tn/7UzML3Jz/88MP25S9/2czMbr31Vjt48KDdeOON1tTUZOedd54999xzqb0zFuhI9ASQiZ4AMtETQCZ6Ap1V1MI7m98VKSsrszlz5ticOXM+6DYBRYOeADLRE0AmegLIRE+gs0onXQMAAAAAAJjZB0w1bw9JkgR/I6b+hsz7WzNV99I2VeKglw6sUiqvvPJKOVYllauvN9PpsSrF0Eyn540aNUqO3bZtm6w//fTTQe2iiy6SY9U2q2RCr+6lTKr0R+98qn32UiVVOmgpUAnOMcmcuSaRel8fk4DerVt4yfHOo5d0me22efPgWFrqifbs2RPUvB9pU/sRcy1S38tM96uXhq3eWOClkV599dVBTfWql6ZdTNS1IibZV12XzMw2b94c1MaMGSPHqoR8L61Wpex780Ndi5uamuRY1ZdeT3n9qu5hXiJsTNKrqnsJ6DFpsbmmzeb69YVAvRFGnbNc066Pfa9sPzfmnKv+8Z4j1LXY6x91r1Ep5WZmu3btkvWYa7Tqt2PvqT7RwYMHg1rMPcUT+yaDE6lzHJNcXwjKysqC+aeueTFv9nn22WflWPW2kU9+8pNyrJrT3jO7SvM+cOCAHKsSzKdNmybHqrWD90wW0yveWkelnXu9rfbPOz4n/sqCmd9r6tnHuxbFrCWzxb94AwAAAACQIhbeAAAAAACkiIU3AAAAAAApYuENAAAAAECKCjZcTQVJ5Rre4o1V4RyeIUOGZP25KixD1cx0uJoXDqW21wvu8eo/+MEPgtoTTzwhx27atCmorVy5Uo5VwUTe8VHhFl4QiApfiDlvpUD1hBJzvPNBnYd8hK/EhEOp4BEVmmimg1LMdMiVF65WXV0d1Lzj3tjYGNQ2btwox27ZsiWoqRA1M7Oampqg5r12RR03FSaS1hxJS9euXd1QlA/KmzcqLCYmdGrr1q1yrLrmqfnsbUNMr3nhQd61tE+fPkEtJjzLE3N/VnMyH6Ft2Sq2nujRo0fw7KDOrzfPcx3rhROqADLvc9Wc9gKf1JxW11wzHR6pwp5O9hlqP7zQqcmTJwe1D33oQ3Ls/v37g5oXsJtruJr39eq4q2tRTPBpIVCBg7mGNXv35VdffTWoqcA1M7N9+/bJuqLOg3c9f++994KatxZQ87Ffv35yrBe+qsLKvO+nttkLJ4zpieuvvz6oedcMdU+IuY/GzB2luO4oAAAAAAAUGRbeAAAAAACkiIU3AAAAAAApYuENAAAAAECKWHgDAAAAAJCigo2FLisrCxJKY9JNvc/MdaxKc/SSOVV6n5dqrlL2vGRb9RmrVq2SY730cZWO+84778ix6rirFHYzfdxiUmFjkgWLLW02V9km/cccl3wcw5i+VPPcSx3ONU3V60uP6quBAwfKsaq39+zZI8eqpPJt27bJse+++25Q89JTH3rooaA2bNgwOValhqpE4lJ9U0A+UrDVOVdprrHUvPOur1VVVUHNe/vFgQMHsqqZ+Wm1qofy0dsxifq53vdjxKStF6rXX389SBZX++D1uqp750a9bcR7xhk5cmRQ8xK+6+vrg1rMtd97jujfv39Q89KXGxoaZF0dS+86oN6g8bvf/U6OVQnM+Xh2UmnLub51xLteFBN1XLxEfvVGijVr1six6hrtpY+r+716k4SZvs57awSVsv/222/Lsb/97W+Dmvc2Fy/tvK6uLqh5b49Rc9o7Puo68Hd/93dyrNpmry9z7StSzQEAAAAAKGAsvAEAAAAASBELbwAAAAAAUsTCGwAAAACAFJVmko6lF5KiPsMLcVLBBzGBaV6YiApGW716tRy7a9cuWVehKDU1NXKsClvxtk0FDHjBCepYqO0yM9uwYUNQ88IiJk2aJOudnQqUyEe4WkxAlQp3ignu8eZzU1NTUPMCZPbv3y/r6rNVIJCZDi1U4ThmOiBE1cx0wOGVV14px15zzTVBTR0Hs9IOTTtx/sUEDsbMf/W53lxSc7eiokKOVaEwXsiPCrdZv369HKvC/rwAQO8arXi9HRN+lZZcr2dpXSPb05o1a4IgprT2S32GCnYyM5syZUrWn+s9JykqdGrQoEFyrJr/KjjLzA+JU2Fs3vVVBWtu3rxZjlU96AU2qXub18Mxva32Q91TCqHXY6j7hDq2Xqiletbcvn27HKt6wgvArK6uDmobN26UY1Vwqrem8b5ftrz7hNfbK1asCGpeD6ve9NZQs2bNCmqXXHKJHKuC1Lx7VVQQmjifuYYTFtcdBQAAAACAIsPCGwAAAACAFLHwBgAAAAAgRSy8AQAAAABIEQtvAAAAAABSVPRRt14yZz4SzHP9XDW2T58+cmxzc3NQ85IFGxsbg5qXqFxVVSXrKmE3JvnX+34q7dJLB1Vpm14KoUo99MZ2JjHpjDFJjDGJtzFJ9mqejx07Vo5VidFeqqaaY17itErIN9PHx+uft956K6ipxHYznX66ePFiOVb15Q9+8AM5VvWgl66bRjJnIUiSJKseyMf9QF2DvHM+ceLEoOalvLa2tga19957T45V+6pS0c10Qq83P7zjo+5B3meons/HcVfztL3v+8WkT58+Qap+WvdKdW5GjBghx55xxhlBTd0PzPT899LA1b556dTq2q/eEmOm08vN9NsvvDfCqOc977qr3oTgXdvUtcRLhlbfL+bNHir1vRTuHeoa4j23qNRu79zEpMgrhw4dknV1v/f6Wo317j8xbzzxxqrv5+3HmjVrsv7c+++/P6h5x1cdi5h56m2DOs+q12LOO//iDQAAAABAilh4AwAAAACQIhbeAAAAAACkiIU3AAAAAAApKqpwtZjglJjQqZjPVb+s7/1S/rZt24JaS0uLHKt+Wd8Ly1ABTNXV1XKsCjsz00EE3jFT+6yCQDzeWBVG4G3DKaecEtQGDx6c9TaUgsOHDwfnUwWExMxnL6Qo1/AUL1BvwIABQa13795yrArC8cJ41H7EjDUzGzRoUFBT887MbOPGjUHN6+0dO3YENXVtMDO7++67g9qoUaPkWBWEQ+Bg7mKOoReo0r9//6DmhWXu27cv6++n5rR3jVdz15vPXvBOfX19UPPud16YTrZyDS6NFRMgWexign/UPdg7Vuo6P378eDlWXee9+0RTU1NQUyFfZjpIzZuLqge9bfDuH2rueSGcMc+haqzX22qsdx1paGgIat79Rx13dW2I2a9CoEI41fO1F6j37rvvBrUePXrIsTHXQTUfvV5Tc8E7D2mN9aiQUW8/1HxSwYtmOrQwKsQs4rqlntPM9POA6h8vaFVuV9YjAQAAAABANBbeAAAAAACkiIU3AAAAAAApYuENAAAAAECKCi5c7dgv9atfVFe/5B7zC/xeYJQa6wXIqEAGL+hl//79Qc0LXmhtbQ1qbW1tcqzaXi+EIyacIyZczRurgg+8MISYAC811gvC8M6d9/WFHhRybPtUeIqa/144lJqn2R6rWN48V/PRO48qrEz1lJm+Xnj94/WEmmOqL73P9gKqYsJLVOhHzPHJNRjs2Bwrlp7wjvmJvGu06h/vnKs57QUzqXPjhR+pOe0FtajvF3NPiZmj3vfz5qPaDy8gVB33mGuRd9+Pmf/ZhqsdO5fF0hPedS8XXv+o7+XNRzVvvP5R8z8mtCqt67aZvm7GHPOYeRRzr4rZj5hnspM9KxZLT6hrr7o2eccw13njjY15ts71edn7etXbsec113ngzUd1H/XuKV6vKOpa4j1bqnuKuj4du5ZlcyzKkgLrnC1bttjQoUM7ejPQidTX19uQIUM6ejNc9ATaGz0BZKIngEz0BJApm54ouIX30aNHbdu2bVZZWWktLS02dOhQq6+vtz59+nT0puXV3r17S3bfzIpj/5IksZaWFhs8eHBBv1qGnigNxbB/9ERhKYY5k4ti2D96orAUw5zJRTHsHz1RWIphzuSiGPYvpicK7kfNu3TpcvxvC479CESfPn0K9mDnqpT3zazw9897/2YhoSdKS6HvHz1ReEp538wKf//oicJTyvtmVvj7R08UnlLeN7PC379se6Jw/6oKAAAAAIASwMIbAAAAAIAUFfTCu7y83O68804rLy/v6E3Ju1LeN7PS37+OUsrHtZT3zaz096+jlPJxLeV9Myv9/esopXxcS3nfzEp//zpKKR/XUt43s9Lbv4ILVwMAAAAAoJQU9L94AwAAAABQ7Fh4AwAAAACQIhbeAAAAAACkiIU3AAAAAAApYuENAAAAAECKCnrh/cADD9jIkSPtlFNOsSlTptjLL7/c0ZsU7aWXXrKrrrrKBg8ebGVlZfbb3/424/8nSWJz5syxwYMHW8+ePW369Om2fPnyjtnYSHfffbedc845VllZaTU1NXbNNdfY6tWrM8YU8/4VInqisNET7Y+eKGz0RPujJwobPdH+6InC1pl6omAX3o899pjdfPPNdscdd9iSJUts2rRpNmvWLNu8eXNHb1qU/fv326RJk+y+++6T//+ee+6xuXPn2n333Wevv/661dXV2YwZM6ylpaWdtzTeggUL7KabbrJFixbZvHnz7PDhwzZz5kzbv3//8THFvH+Fhp4o/DlDT7QveqLw5ww90b7oicKfM/RE+6InCn/OdKqeSArUueeem3z961/PqI0bNy657bbbOmiLcmdmyZNPPnn8v48ePZrU1dUlP/zhD4/XDh06lFRVVSX/9E//1AFbmJvt27cnZpYsWLAgSZLS27+ORk8U35yhJ9JFTxTfnKEn0kVPFN+coSfSRU8U35wp5Z4oyH/xbmtrs8WLF9vMmTMz6jNnzrSFCxd20Fbl34YNG6yxsTFjP8vLy+3iiy8uyv1sbm42M7P+/fubWentX0eiJ4pzztAT6aEninPO0BPpoSeKc87QE+mhJ4pzzpRyTxTkwnvnzp125MgRq62tzajX1tZaY2NjB21V/h3bl1LYzyRJ7JZbbrELL7zQJkyYYGaltX8djZ4ovv2kJ9JFTxTfftIT6aInim8/6Yl00RPFt5+l3hPdOnoDTqasrCzjv5MkCWqloBT2c/bs2bZ06VL74x//GPy/Uti/QtFZjmUp7Cc90T46y7Eshf2kJ9pHZzmWpbCf9ET76CzHshT2s9R7oiD/xbu6utq6du0a/C3G9u3bg7/tKGZ1dXVmZkW/n9/85jftqaeeshdffNGGDBlyvF4q+1cI6Ini2k96In30RHHtJz2RPnqiuPaTnkgfPVFc+9kZeqIgF949evSwKVOm2Lx58zLq8+bNswsuuKCDtir/Ro4caXV1dRn72dbWZgsWLCiK/UySxGbPnm1PPPGEvfDCCzZy5MiM/1/s+1dI6InimDP0RPuhJ4pjztAT7YeeKI45Q0+0H3qiOOZMp+qJdotxi/TrX/866d69e/LQQw8lK1asSG6++eakV69eycaNGzt606K0tLQkS5YsSZYsWZKYWTJ37txkyZIlyaZNm5IkSZIf/vCHSVVVVfLEE08ky5YtSz7/+c8ngwYNSvbu3dvBW/7XfeMb30iqqqqS+fPnJw0NDcf/HDhw4PiYYt6/QkNPFP6coSfaFz1R+HOGnmhf9EThzxl6on3RE4U/ZzpTTxTswjtJkuT+++9Phg8fnvTo0SOZPHny8Vj5YvLiiy8mZhb8uf7665Mk+XNE/p133pnU1dUl5eXlyUUXXZQsW7asYzc6S2q/zCx5+OGHj48p5v0rRPREYaMn2h89UdjoifZHTxQ2eqL90ROFrTP1RFmSJEl+/u0cAAAAAACcqCB/xxsAAAAAgFLBwhsAAAAAgBSx8AYAAAAAIEUsvAEAAAAASBELbwAAAAAAUsTCGwAAAACAFLHwBgAAAAAgRSy8AQAAAABIEQtvAAAAAABSxMIbAAAAAIAUsfAGAAAAACBF/x+6eEHlkO1bzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_images(train_df.drop(columns='label'), train_df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19b53ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.countplot(x=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fb63fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNEAAAIJCAYAAACLEasGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+sUlEQVR4nO3deZhUhZ0v/F9VdyMtIt2o4xKZ6yuLXhUiiwvi1UhsSQYRguASQsSZxFwlMZk3osYlegdxiTExxDFRkDBGniHBiIohShZjYiKbEnR8LgpkEYNBaZqWrQW66v3D1449LKebpU8d+Hyeh+fpPqdKvj9OVZ06X8+pyhWLxWIAAAAAADuUTzsAAAAAAJQ6JRoAAAAAJFCiAQAAAEACJRoAAAAAJFCiAQAAAEACJRoAAAAAJFCiAQAAAEACJRoAAAAAJFCiAQAAAEACJRoAAAAAJChPO0BaamvXRbGYdgoAAAAA0pLLRRxySMcW3Xa/LdGKxVCiAQAAANAiLucEAAAAgARKNAAAAABIoEQDAAAAgARKNAAAAABIoEQDAAAAgARKNAAAAABIoEQDAAAAgARKNAAAAABIoEQDAAAAgARKNAAAAABIoEQDAAAAgARKNAAAAABIoEQDAAAAgASplGizZ8+OE044IXr37t30Z9y4cRERsXjx4hg5cmT07t07Bg4cGDNmzGh235kzZ0ZNTU2cfPLJMXz48Fi0aFEaIwAAAACwHylP4y995ZVXYujQoXHHHXc0W15fXx9XXHFFXH311XHxxRfHggULYuzYsXHcccdFr169Yt68eTF+/PiYNGlS9OrVK6ZNmxZXXnllPPvss1FZWZnGKAAAAADsB1I5E+2VV16Jk046aZvlc+bMiaqqqhg1alSUl5dH//79Y8iQITFt2rSIiJgxY0YMHjw4+vbtGxUVFTFmzJiorq6O2bNnt/UIAAAAAOxH2vxMtEKhEK+++mpUVlbG5MmTo7GxMc4+++y45pprYunSpdGjR49mt+/WrVs8+uijERGxbNmyuPDCC7dZv2TJklbnyOV2fQYAAAAAsq81/VCbl2hr1qyJE044IQYNGhQTJ06Murq6uO6662LcuHFx2GGHbXNZZvv27WPjxo0REbFhw4adrm+NQw7puOtDAAAAALBfafMS7dBDD226PDMiorKyMsaNGxcXXXRRDB8+PBoaGprdvqGhITp06NB02+2tr66ubnWO2tp1USzuwgCwj8rnc5Er0VM0i8ViFAqesAAAAOxZuVzLT7Rq8xJtyZIl8dRTT8VXv/rVpgP2zZs3Rz6fj169esV//Md/NLv9smXLonv37hER0b1791i6dOk2688666xW5ygWQ4kG/798PhdVVZWRz5elHWW7CoXGqKvbpEgDAAAgNW1eolVVVcW0adOiU6dOcfnll8fbb78dd999d3zqU5+KQYMGxT333BNTp06NUaNGxYsvvhizZs2K+++/PyIiRowYEWPHjo1PfvKT0bdv35g2bVrU1tZGTU1NW48B+5R8Phf5fFm8/OtvxPq1K9KO08xBVV2i18eujXw+p0QDAAAgNblise3Px5o/f35861vfitdffz0OOOCAGDx4cIwbNy4OOOCAeOWVV2LChAnx+uuvR+fOneOqq66K4cOHN933iSeeiO9973uxatWq6NatW9x0003x0Y9+tNUZVq92OSd8oLw8H9XVHeL3j38p1tUuTztOMx0P6RpnDPtu1NVtiK1bC2nHAQAAYB+Sy0UcemjLLudMpUQrBUo0+DslGgAAAPuj1pRo+b2cBQAAAAAyT4kGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAmUaAAAAACQQIkGAAAAAAnK0w4AwL4hn89FPp9LO8Z2FQrFKBSKaccAAAAyTIkGwG7L53NRVV0ZZfmytKNsV2OhMdbWbVKkAQAAu0yJBsBuy+dzUZYvi8fn3hm1765IO04zhxzcJYadfn3k8zklGgAAsMuUaPsIl1EBpaD23RXxt7placcAAADY45Ro+4B8Phedqw+MXL40vyeiWCjEmrqNijQAAAAgs5Ro+4B8Phe5fD7qf/FUbK2rTTtOM+XVh0Snc893GRUAAACQaUq0fcjWutrYuvrttGMAAAAA7HNK8/o/AAAAACghSjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAEqZZojY2NMXr06Lj++uubli1evDhGjhwZvXv3joEDB8aMGTOa3WfmzJlRU1MTJ598cgwfPjwWLVrU1rEBAAAA2M+kWqLdd999sXDhwqbf6+vr44orrohhw4bFggULYsKECXHHHXfEyy+/HBER8+bNi/Hjx8edd94ZCxYsiAsuuCCuvPLK2LRpU1ojAAAAALAfSK1Ee+GFF2LOnDlx3nnnNS2bM2dOVFVVxahRo6K8vDz69+8fQ4YMiWnTpkVExIwZM2Lw4MHRt2/fqKioiDFjxkR1dXXMnj07rTEAAAAA2A+Up/GX1tbWxo033hj3339/TJ06tWn50qVLo0ePHs1u261bt3j00UcjImLZsmVx4YUXbrN+yZIlrc6Qy7U+N7vHvzm7y2OI3eUxBAAAfFhrjhHavEQrFAoxbty4uPzyy+P4449vtm7Dhg1RWVnZbFn79u1j48aNLVrfGocc0rHV92HXVVd3SDsCGecxxO7yGAIAAHZHm5doDzzwQLRr1y5Gjx69zbrKyspYt25ds2UNDQ3RoUOHpvUNDQ3brK+urm51jtradVEstvpuJamsLF/yB4d1dRuisbGQdgx2wGOI3eUxBAAAZFEu1/ITrdq8RHviiSfi7bffjn79+kVENJViv/jFL+Laa6+N3/3ud81uv2zZsujevXtERHTv3j2WLl26zfqzzjqr1TmKxdhnSrSs8O/N7vIYYnd5DAEAALuqzb9Y4Omnn46XXnopFi5cGAsXLozzzz8/zj///Fi4cGHU1NTE6tWrY+rUqbFly5aYO3duzJo1q+lz0EaMGBGzZs2KuXPnxpYtW2Lq1KlRW1sbNTU1bT0GAAAAAPuRVL5YYEeqq6tjypQpMWHChJg4cWJ07tw5brrppjj99NMjIqJ///5xyy23xK233hqrVq2Kbt26xaRJk6Kqqird4AAAAADs01Iv0e68885mv/fs2TOmT5++w9sPHTo0hg4durdjAQC0Wj6fi3y+NL8GtlAoRqHgmmYAgF2VeokGALAvyOdzUVV9YJTl2/zTMlqksVCItXUbFWkAALtIiQYAsAfk87koy+fj7vm/ihXr6tKO00yXjtUx7tSBkc/nlGgAALtIiQYAsAetWFcXy9fWph0DAIA9rDSvNwAAAACAEqJEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAE5WkHAOB9+Xwu8vlc2jG2q1AoRqFQTDsGAABAapRoACUgn89FdXVl5PNlaUfZrkKhMerqNinSAPYy/0MFAEqXEg2gBLx/0FQWv3z+zlhbvyLtOM1UdeoSHz/z+sjncw6eAPaifD4XVdUHRlm+ND9xpbFQiLV1G+0LYD+g0IftU6IBlJC19Sti9ZplaccAIAX5fC7K8vn41rz/ijfXbUw7TjNHdzww/t/TTvI/VGA/8P4VEh1KukSrq9vgtYhUKNEAAKCEvLluY/xx7bq0YwD7qQ/OQnvnZ2tjy5qtacdppqJzeRz2ySqFPqlRogEAAADNbFmzNTa/U1olGqStND9wAQAAAABKiBINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABKUpx0AAAAAgH1HPp+LfD6XdoztKhSKUSgUd+m+SrTYdzcuAPsX+zMAANKWz+eic/WBkcuX5sWPxUIh1tRt3KX3pvt9ibYvb1wA9h/5fC6qqg+MshLdnzUWCrHW/gwAYJ+Xz+cil89H/ZzF0Vi3Pu04zZRVHxSdzvto5PM5Jdqu+GDjvvuL56Ox7t204zRTVn1wHHzumbu8cQHYf+TzuSjL5+MbC6fFinWr0o7TTJeOh8e1/UbZnwEA7Eca69bH1ndKq2fZXft9ifaBxrp3Y+vqNWnHAIDdsmLdqlhe/9e0YwAAwD6nNK/5AAAAAIASokQDAAAAgARKNAAAAABIoEQDAAAAgARKNAAAAABIoEQDAAAAgARKNAAAAABIoEQDAAAAgARKNAAAAABIoEQDAAAAgARKNAAAAABIoEQDAAAAgARKNAAAAABIoEQDAAAAgARKNAAAAABIUJ52AIiIyOdzkc/n0o6xXYVCMQqFYtoxAAAAgBQp0UhdPp+L6urKyOfL0o6yXYVCY9TVbVKkAQAAwH5MiUbq3j8LrSxWP/Od2LLmzbTjNFPR+eg4dNCXI5/PKdEAAABgP6ZEo2RsWfNmbHnnT2nHAAAAANiGLxYAAAAAgASplGgvvPBCjBw5Mvr06RMDBgyI8ePHR0NDQ0RELF68OEaOHBm9e/eOgQMHxowZM5rdd+bMmVFTUxMnn3xyDB8+PBYtWpTGCAAAAADsR9q8RFuzZk184QtfiEsvvTQWLlwYM2fOjPnz58eDDz4Y9fX1ccUVV8SwYcNiwYIFMWHChLjjjjvi5ZdfjoiIefPmxfjx4+POO++MBQsWxAUXXBBXXnllbNq0qa3HAAAAAGA/0uYlWufOneP3v/99DB8+PHK5XKxduzbee++96Ny5c8yZMyeqqqpi1KhRUV5eHv37948hQ4bEtGnTIiJixowZMXjw4Ojbt29UVFTEmDFjorq6OmbPnt3WYwAAAACwH0nlcs6DDjooIiLOPvvsGDJkSBx22GExfPjwWLp0afTo0aPZbbt16xZLliyJiIhly5btdD0AAAAA7A2pfjvnnDlzor6+Pq655pq4+uqr4/DDD4/Kyspmt2nfvn1s3LgxIiI2bNiw0/Wtkcvteu40ZC3v9mR9hqzn3xfYBunL+jbIev59gW2QPtuA3eUxBJQCr0Xsrg8eQ615LKVaorVv3z7at28f48aNi5EjR8bo0aNj3bp1zW7T0NAQHTp0iIiIysrKpi8g+PD66urqVv/dhxzScdeDt7Hq6g5pR9htWZ8h6/n3BbZB+rK+DbKef19gG6TPNmB3eQwBpcBrEbtrVx9DbV6ivfTSS3HDDTfEk08+Ge3atYuIiM2bN0dFRUV069Ytfve73zW7/bJly6J79+4REdG9e/dYunTpNuvPOuusVueorV0XxWJEWVm+5J+AdXUborGxsMP1WZ8h6/n3BbZB+rK+DbKef19gG6TPNmB3eQwBpcBrEbsra4+hXK7lJ1q1eYl23HHHRUNDQ9xzzz3x1a9+Nd5555246667YsSIETFo0KC45557YurUqTFq1Kh48cUXY9asWXH//fdHRMSIESNi7Nix8clPfjL69u0b06ZNi9ra2qipqWl1jmLx/T9ZkaWsO5L1GbKef19gG6Qv69sg6/n3BbZB+mwDdpfHEFAKvBaxu3blMdTmJVqHDh1i8uTJcfvtt8eAAQOiY8eOMWTIkBg7dmy0a9cupkyZEhMmTIiJEydG586d46abborTTz89IiL69+8ft9xyS9x6662xatWq6NatW0yaNCmqqqraegwAAAAA9iOpfCZat27dYsqUKdtd17Nnz5g+ffoO7zt06NAYOnTo3ooGAAAAANvIpx0AAAAAAEqdEg0AAAAAEqRyOScAAKUpn89FPp9LO8Y2CoViFAo+RRoASI8SDQCAiHi/QKuqPjDK8qV3sUJjoRBr6zYq0gCA1CjRAOD/V6pn4EQ4C4e2kc/noiyfj2/O+12sWFefdpwmXTp2imtOGxD5fM7zAABIjRINAOKDM3AqoyxflnaU7WosNMbauk0KBNrEinX1sXxtXdoxAABKihINAOKDM3DK4oEFd8Vb61akHaeZIzt2iS+ccp2zcAAAIEVKNAD4kLfWrYi/1C9LOwYAAFBiSu9TYwEAAACgxCjRAAAAACCBEg0AAAAAEijRAAAAACCBEg0AAAAAEijRAAAAACBBq0u0K6+8crvLP/OZz+x2GAAAAAAoReUtudGbb74Zjz/+eEREPP/883Hfffc1W79+/fp47bXX9ng4AAAAACgFLSrRjjrqqFi6dGmsWbMmGhsbY968ec3WH3DAAXHLLbfslYAAAAAAkLYWlWj5fD6+853vRETETTfdFLfddtteDQUAAAAApaRFJdqH3XbbbbF58+ZYs2ZNFAqFZuuOOuqoPRYMAAAAAEpFq0u0p59+Om6++eZYv35907JisRi5XC7+7//9v3s0HAAAAACUglaXaBMnToxRo0bFpz71qSgvb/XdAQAAACBzWt2CvfXWW/HFL35RgQYAAADAfiPf2juceOKJsWzZsr2RBQAAAABKUqtPJ+vTp0+MGTMmPvGJT8Shhx7abN0Xv/jFPRYMAAAAYH+Uz+cin8+lHWO7CoViFArFtGOkotUl2qJFi6J79+6xfPnyWL58edPyXK40Ny4AAAC0pVItQPbn8iNL8vlcdK4+MHL5Vl882CaKhUKsqdu4Xz6WWl2i/fCHP9wbOQAAACDz8vlcVFd3KNkSra5uw35ZfmRJPp+LXD4f9U8vja1rNqUdp5nyzpXR6RPdI5/P7ZePo1aXaI8//vgO1w0bNmw3ogAAAEC2fXAW2vLn6qOhvjHtOE3adyqLrmd32m/LjyzaumZTbH1nQ9ox+JBWl2gTJ05s9nt9fX1s2rQp+vbtq0QDAACAiGiob4yNtVvTjgHsQa0u0X71q181+71YLMakSZNi7dq1eyoTAAAAAJSU3f6UulwuF//yL/8STzzxxJ7IAwAAAAAlZ4981cOf/vQn384JAAAAwD6r1Zdzjh49ullhtmXLlnjttdfiggsu2KPBAAAAAKBUtLpEO+2005r9ns/nY8yYMXHuuefusVAAAAAAUEpaXaJ98YtfbPq5trY2OnXqFOXlrf7PAAAAAEBmtPoz0bZs2RK333579O7dO84888zo27dv3HzzzbF58+a9kQ8AAAAAUtfqEu3++++PefPmxb333htPPfVU3HvvvbF48eK4995790I8AAAAAEhfq6/DnDVrVvzgBz+ILl26RERE165do2vXrjFq1Ki49tpr93hAAAAAAEhbq89Eq6+vjyOPPLLZsiOPPDIaGhr2WCgAAAAAKCWtLtGOO+64mD59erNl06dPjx49euyxUAAAAABQSlp9OedXvvKV+Od//ud48skno0uXLvHGG2/EsmXL4qGHHtob+QAAAAAgda0u0fr16xc33nhjLF68OMrLy+Occ86Jiy66KPr06bM38gG0WD6fi3w+l3aMbRQKxSgUimnHAADIhFJ9TxfhfR3s71pdok2cODFmzpwZP/jBD+KYY46JX/7yl3H77bdHfX19fO5zn9sbGQES5fO5qK6ujHy+LO0o2ygUGqOubpM3XABtwME3ZPt58P57ug4lnb+uboPnMuynWl2iPfroozFt2rSmb+f8+Mc/Ht27d4/LLrtMicZ+rVTfrOwvb9jf//cvi7nP3RXv1q9IO06Tgzt1idPPvi7y+dx+sR0A0pTP56Kq+sAoy7f6Y3/bRGOhEGvrNtofsFdlvYT64D314rnrYv27W9s43c4ddHB5fPT0jt7XwX6s1SXa+vXrt/vtnBs3btxjoSBrnAVVOt6tXxF1tcvSjgFACvL5XJTl8/HNeQvjzXXr0o7TzNEdO8Y1p/Vz8M1e90EJ9eyC+li7rjHtOM1UdSyLc07p1KLnwfp3t8a7daWVH6DVJdqJJ54YDz74YFx11VVNy6ZMmRLHH3/8Hg0GWfLBWVDLf/nNaFj7ZtpxmrSvOjq6fvwab9gB2K+8uW5dLF9bn3YMSNXadY1Ru7a0zuQCyLpWl2jXX399/PM//3P8+Mc/jiOOOCL+9re/xdatW2Py5Ml7Ix9kSsPaN2Pj6uVpxwAAAAD2sF06E23OnDnx7LPPxttvvx1HHnlkfOxjH4uOHTvujXwAAAAAkLpWl2gREZ06dYphw4bt4SgAAAAAUJpK86uLAAAAAKCEKNEAAAAAIIESDQAAAAASKNEAAAAAIIESDQAAAAASKNEAAAAAIIESDQAAAAASKNEAAAAAIIESDQAAAAASKNEAAAAAIIESDQAAAAASKNEAAAAAIIESDQAAAAASKNEAAAAAIIESDQAAAAASKNEAAAAAIIESDQAAAAASKNEAAAAAIIESDQAAAAASKNEAAAAAIIESDQAAAAASKNEAAAAAIIESDQAAAAASKNEAAAAAIIESDQAAAAASKNEAAAAAIEF52gEAAD6Qz+cin8+lHWMbhUIxCoVi2jEAAEiREg0AKAn5fC6qqg+MsnzpnSjfWCjE2rqNijQAgP2YEg0AKAn5fC7K8vm4e8FTsWJdbdpxmnTpeEiMO+X8yOdzSjQAgP2YEg0AKCkr1tXG8vq3044BAGSYj4hgb1CiAQAAAPuMfD4Xnas7RK4ES7RioRhr6jYo0jIqlRJtyZIlcdddd8Wrr74aFRUVMWDAgLj++uujc+fOsXjx4rjtttti2bJlUV1dHVdeeWWMHDmy6b4zZ86M+++/P95555049thj4+abb47evXunMQYAAABQYvL5XOTyuVj705Wxdc17acdpUt75gKgafJSPiMiwNi/RGhoa4nOf+1xcdNFF8cADD8SGDRviuuuuixtuuCHuuuuuuOKKK+Lqq6+Oiy++OBYsWBBjx46N4447Lnr16hXz5s2L8ePHx6RJk6JXr14xbdq0uPLKK+PZZ5+NysrKth4FAAAAKFFb17wXW98unRKN7Gvzr79auXJlHH/88TF27Nho165dVFdXNxVmc+bMiaqqqhg1alSUl5dH//79Y8iQITFt2rSIiJgxY0YMHjw4+vbtGxUVFTFmzJiorq6O2bNnt/UYAAAAAOxH2vxMtGOPPTYmT57cbNkzzzwTJ554YixdujR69OjRbF23bt3i0UcfjYiIZcuWxYUXXrjN+iVLlrQ6R670Lo3eqazl3Z6szyB/+rI+Q9bzR2R/hqznj8j+DPKnL+szZD1/RPZnyHp+SkPWH0fypy/rM2Q9f0T2Z/ggf2vmSPWLBYrFYtx7773x7LPPxiOPPBIPP/zwNpdltm/fPjZu3BgRERs2bNjp+tY45JCOux68jVVXd0g7wm7L+gzypy/rM2Q9f0T2Z8h6/ojszyB/+rI+Q9bzR2R/hqznpzRk/XEkf/qyPkPW80dkf4ZdzZ9aibZ+/fr42te+Fq+++mo88sgjcdxxx0VlZWWsW7eu2e0aGhqiQ4f3h6usrIyGhoZt1ldXV7f676+tXRfFYkRZWb7kN35d3YZobCzscH3WZ8h6/ojSnyHr+SOyP0PW80d4HpcC2yBdWc8fkf0Zsp4/Yt9/HpO+rD+Osp4/ovRnyHr+iOzPkPX8EfvW8ziXa/mJVqmUaG+88UZ8/vOfj6OOOioeffTR6Ny5c0RE9OjRI373u981u+2yZcuie/fuERHRvXv3WLp06TbrzzrrrFZnKBbf/5MVWcq6I1mfQf70ZX2GrOePyP4MWc8fkf0Z5E9f1mfIev6I7M+Q9fyUhqw/juRPX9ZnyHr+iOzPsCv52/yLBerr6+Oyyy6LPn36xEMPPdRUoEVE1NTUxOrVq2Pq1KmxZcuWmDt3bsyaNavpc9BGjBgRs2bNirlz58aWLVti6tSpUVtbGzU1NW09BgAAAAD7kTY/E+2xxx6LlStXxs9+9rN4+umnm61btGhRTJkyJSZMmBATJ06Mzp07x0033RSnn356RET0798/brnllrj11ltj1apV0a1bt5g0aVJUVVW19RgAAAAA7EfavES7/PLL4/LLL9/h+p49e8b06dN3uH7o0KExdOjQvRENAAAAALarzS/nBAAAAICsUaIBAAAAQAIlGgAAAAAkUKIBAAAAQAIlGgAAAAAkUKIBAAAAQAIlGgAAAAAkUKIBAAAAQAIlGgAAAAAkUKIBAAAAQAIlGgAAAAAkUKIBAAAAQAIlGgAAAAAkUKIBAAAAQAIlGgAAAAAkUKIBAAAAQAIlGgAAAAAkUKIBAAAAQAIlGgAAAAAkUKIBAAAAQAIlGgAAAAAkUKIBAAAAQAIlGgAAAAAkUKIBAAAAQAIlGgAAAAAkKE87AAAAsO/I53ORz+fSjrFdhUIxCoVi2jEAyCglGgAAsEfk87moqu4QZSVaojUWirG2boMiDYBdokQDAAD2iHw+F2X5XHxn/p/izXUNacdp5uiO7ePLp/4/kc/nlGgA7BIlGgAAsEe9ua4h/rR2U9oxAGCP8sUCAAAAAJBAiQYAAAAACZRoAAAAAJBAiQYAAAAACZRoAAAAAJBAiQYAAAAACZRoAAAAAJBAiQYAAAAACZRoAAAAAJBAiQYAAAAACZRoAAAAAJBAiQYAAAAACZRoAAAAAJCgPO0AAAAApSKfz0U+n0s7xnYVCsUoFIppxwDYbynRAAAA4v0Craq6Q5SVaInWWCjG2roNijSAlCjRAAAA4v0SrSyfi4cX1Mbf1m1JO04zR3SsiM+eckjk8zklGkBKlGgAAAAf8rd1W+LN+tIq0QBIny8WAAAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASKBEAwAAAIAESjQAAAAASJBqibZmzZqoqamJefPmNS1bvHhxjBw5Mnr37h0DBw6MGTNmNLvPzJkzo6amJk4++eQYPnx4LFq0qK1jAwAAALCfSa1Ee/HFF+Piiy+ON954o2lZfX19XHHFFTFs2LBYsGBBTJgwIe644454+eWXIyJi3rx5MX78+LjzzjtjwYIFccEFF8SVV14ZmzZtSmsMAAAAAPYDqZRoM2fOjGuuuSb+9V//tdnyOXPmRFVVVYwaNSrKy8ujf//+MWTIkJg2bVpERMyYMSMGDx4cffv2jYqKihgzZkxUV1fH7Nmz0xgDAAAAgP1EKiXamWeeGT//+c/jn/7pn5otX7p0afTo0aPZsm7dusWSJUsiImLZsmU7Xd8audz7f7Lig7zb+5MV+2r+rMyQ9fwR2Z8h6/kj9t38+8IMWZH1bZD1/BHZnyHr+SP23fz7wgxZYRukL+vbIOv5I7I/Q9bzR+xb+VuqfO/F2bHDDjtsu8s3bNgQlZWVzZa1b98+Nm7c2KL1rXHIIR1bfZ+0VFd3SDvCbsv6DPKnL+szZD1/RPZnyHr+iOzPIH/6sj5D1vNHZH+GrOePyP4MWc8fkf0Z5E9f1mfIev6I7M+wq/lTKdF2pLKyMtatW9dsWUNDQ3To0KFpfUNDwzbrq6urW/131daui2IxoqwsX/Ibv65uQzQ2Fna4PuszZD1/ROnPkPX8EdmfIev5IzyPS4FtkK6s54/I/gxZzx/heVwKbIP02Qbpynr+iOzPkPX8EfvW8ziXa/mJViVVovXo0SN+97vfNVu2bNmy6N69e0REdO/ePZYuXbrN+rPOOqvVf1ex+P6frMhS1h3J+gzypy/rM2Q9f0T2Z8h6/ojszyB/+rI+Q9bzR2R/hqznj8j+DFnPH5H9GeRPX9ZnyHr+iOzPsCv5U/t2zu2pqamJ1atXx9SpU2PLli0xd+7cmDVrVlx44YURETFixIiYNWtWzJ07N7Zs2RJTp06N2traqKmpSTk5AAAAAPuykjoTrbq6OqZMmRITJkyIiRMnRufOneOmm26K008/PSIi+vfvH7fcckvceuutsWrVqujWrVtMmjQpqqqq0g0OAAAAwD4t9RLttddea/Z7z549Y/r06Tu8/dChQ2Po0KF7OxYAAAAANCmpyzkBAAAAoBQp0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABIo0QAAAAAggRINAAAAABJkskSrra2Nq666Kvr16xennXZaTJgwIbZu3Zp2LAAAAAD2UZks0b7yla/EgQceGL/97W/j0UcfjRdeeCGmTp2adiwAAAAA9lGZK9H+8pe/xPz582PcuHFRWVkZXbp0iauuuiqmTZuWdjQAAAAA9lHlaQdoraVLl0ZVVVUcfvjhTcu6du0aK1eujHfffTcOPvjgFv138vmIYvHvv5cdWh1RXlr/HGVVHZt+zreg7iw/9PDIlVfsxUStV1bVuennpBnaHXZs5MoP2MuJWqei+iNNP7dkG1QecmzkS2iGAzq1Lv/Bh3SNsvL2ezFR63Vo5QzVnUtrhoMPbl3+Qzp3jfISyh8R0akVMxxe3TUqykorf+dWboN/7NQ1DiixGQ4/qOUzdO30kWhf1m4vJ2qdjxx0WNPPLdkGXTsdHu3LSmd/9pGDWr4vi4jo2unQaF9WWu8pPnJQVdPPLZqhqnMcUEIzHN3x7+/vWpL/2KpOcUBZ2V5M1Hof6XhQ089JMxxbdVAcUFZa/6/7Ix0PbPq5RdugU2XpzXDQ39+jJc3QpVO7aFeW28uJWufwg/7+utii9xSdyqK8tJ4G0emgvwdKmuHg6vIosadxdDj476+LLTo26FwW+dJ5KY0DDm75v39ERLt/KI9ceWk9Dyo6t26G8n9oH7mK0pmhrLrlr0MREeWHdYhceWm9lpZVVzb9nDRD2aEHR6m9EJVVdWj6+YP8uVY8RHLF4oerpNL3xBNPxLe//e349a9/3bTsjTfeiJqamnjuuefiiCOOSC8cAAAAAPuk0qo0W+DAAw+MTZs2NVv2we8dOnTY3l0AAAAAYLdkrkTr3r17rF27NlavXt20bPny5XHEEUdEx44dd3JPAAAAANg1mSvRjjnmmOjbt2/cfvvtsX79+lixYkXcf//9MWLEiLSjAQAAALCPytxnokVErF69Ov7t3/4t5s2bF/l8PoYNGxbXXHNNlJXaJ08CAAAAsE/IZIkGAAAAAG0pc5dzAgAAAEBbU6IBAAAAQAIlGgAAAAAkUKIBAAAAQAIl2h5SW1sbV111VfTr1y9OO+20mDBhQmzdujXtWLtkzZo1UVNTE/PmzUs7SqssWbIkLr/88jj11FNjwIABce2118aaNWvSjtUqL7zwQowcOTL69OkTAwYMiPHjx0dDQ0PasVqtsbExRo8eHddff33aUVpt9uzZccIJJ0Tv3r2b/owbNy7tWC22du3auPbaa+O0006LU045Ja666qp4++23047VYk8++WSzf/vevXvHSSedFCeddFLa0Vrs1VdfjVGjRkW/fv3izDPPjNtuuy02b96cdqxE23vtX7x4cYwcOTJ69+4dAwcOjBkzZqSYMNmO9l+LFi2Knj17ppSq5baX/5lnnomhQ4dGnz59YuDAgXHfffdFoVBIMeXObW+GadOmxXnnnRe9e/eO8847Lx555JEUE+7czt4Dvf3223HGGWfEY489lkKyltveDLfcckucdNJJzV5bf/SjH6WYcse2l3/JkiVx2WWXRe/eveOMM86IO+64o6TfZ//3Gb7+9a9vs2/7n//zf8a//Mu/pJx0+7a3DX7605/GJz/5yejTp08MGjQo/vM//zPFhDu3vfzPPfdcDBs2LHr37h0XXHBB/PznP08x4Y7t7HgmC/vklhyPlfo+eWczZGGfvLP8Wdgft+QxlPr+uMge8ZnPfKb41a9+tbhx48biG2+8URw8eHBx0qRJacdqtYULFxbPPffcYo8ePYpz585NO06Lbdq0qThgwIDid77zneJ7771XXLNmTfHzn/988Qtf+ELa0Vqstra22LNnz+JPfvKTYmNjY3HVqlXF888/v/id73wn7Witdu+99xaPP/744nXXXZd2lFa78847i9dff33aMXbZZz7zmeLYsWOL9fX1xXXr1hW/+MUvFq+44oq0Y+2yv/3tb8UBAwYUH3/88bSjtEhjY2NxwIABxf/4j/8oNjY2Ft96663ioEGDivfdd1/a0XZqe6/9a9euLZ566qnFRx55pLhly5bi73//+2Lv3r2LixcvTjnt9m1vhkKhUJwxY0bx5JNPLvbo0SPlhDu3vfyvvPJKsVevXsVf/epXxcbGxuKyZcuK55xzTvGhhx5KOe32bW+GX/7yl8VTTjml+MorrxSLxWJx8eLFxZ49exZfeOGFNKNu187eAzU2NhZHjx5dPP7444s/+clPUkqYbEczfOpTnyo+9thjKSZrme3lr62tLZ522mnF73//+8XNmzcXV6xYUTzvvPOKkydPTjnt9rXkvfRvf/vb4qmnnlp8/fXX2zhdsu3lf+2114of/ehHi4sWLSoWi8Xiiy++WDzxxBOLCxYsSDHp9m0v/3/9138VTzzxxOKPf/zj4pYtW4oLFiwo9u7du+SOdXZ2PJOFfXLS8VgW9sk7myEL++Sd5c/C/rglx/SlsD92Jtoe8Je//CXmz58f48aNi8rKyujSpUtcddVVMW3atLSjtcrMmTPjmmuuiX/9139NO0qrrVy5Mo4//vgYO3ZstGvXLqqrq+Piiy+OBQsWpB2txTp37hy///3vY/jw4ZHL5WLt2rXx3nvvRefOndOO1iovvPBCzJkzJ84777y0o+ySV155JVNnPX3Yf/3Xf8XixYvjzjvvjIMPPjgOOuigGD9+fFxzzTVpR9slxWIxxo0bFx/72Mdi6NChacdpkfr6+njnnXeiUChEsViMiIh8Ph+VlZUpJ9uxHb32z5kzJ6qqqmLUqFFRXl4e/fv3jyFDhpTkvm1HM9xwww0xY8aMuPrqq1NK1jI7yv/Xv/41LrnkkjjnnHMin89H165do6ampiT3bTuaYeDAgfGrX/0qTjrppNi6dWvU1dVFLpeLgw8+OKWk25f0Hujf//3f44gjjogjjzyyjZO13I5m2Lx5c7z++uslv2/bUf7HH388jjnmmPjCF74QFRUVcfTRR8eUKVPik5/8ZEpJd6wl76XXrFkT11xzTdx4443RvXv3NkyXbEf5//znP8fWrVub9m25XC7KysqiXbt2KSXdvh3l/9nPfhZ9+vSJkSNHRnl5efTr1y+GDBlScmfT7ex4Jgv75KTjsSzsk3c2Qxb2yTvLn4X9cUuO6Uthf6xE2wOWLl0aVVVVcfjhhzct69q1a6xcuTLefffdFJO1zplnnhk///nP45/+6Z/SjtJqxx57bEyePDnKysqalj3zzDNx4oknppiq9Q466KCIiDj77LNjyJAhcdhhh8Xw4cNTTtVytbW1ceONN8Y999xT0qXBjhQKhXj11Vfj17/+dZxzzjlx1llnxc033xz19fVpR2uRl19+Obp16xY//vGPo6amJs4888y466674rDDDks72i554oknYtmyZZm6LLi6ujrGjBkTd911V/Ts2TPOPvvsOOaYY2LMmDFpR9uhHb32L126NHr06NFsWbdu3WLJkiVtGa9FdjTDl7/85fjRj34UJ5xwQkrJWmZH+QcNGhRf+9rXmn5vaGiIX//61yW5b9vZe4iDDjoo/vjHP0avXr3iiiuuiEsvvbTktsnO8s+dOzd++tOfxi233JJCspbb0QxLliyJrVu3xsSJE+OMM86IQYMGxYMPPlhylyDtKP/LL78cPXr0iK9//esxYMCAOPfcc+PJJ5+MI444IqWkO9aS99Lf/OY346STTooLLrigDZO1zI7yn3nmmXHyySfHpZdeGieeeGJccskl8eUvfzl69eqVUtLt21H+xsbGOPDAA5sty+fz8cc//rEt4yXa2fFMFvbJScdjWdgn72yGLOyTk7ZBqe+Pk/KXyv5YibYHbNiwYZvC4IPfN27cmEakXXLYYYdFeXl52jF2W7FYjG9/+9vx7LPPxo033ph2nF0yZ86c+M1vfhP5fL6k/2/NhxUKhRg3blxcfvnlcfzxx6cdZ5esWbMmTjjhhBg0aFDMnj07pk+fHn/+858z85lo9fX18dprr8Wf//znmDlzZjz++OOxatWquO6669KO1mqFQiG+973vxf/+3/+7qVzOgkKhEO3bt4+bb745/vCHP8RTTz0Vy5cvj4kTJ6YdbYd29Nq/vX1b+/btS3K/tqMZSvEge3tasv9dv359jB07Ntq3b1+SpWzSDF26dInFixfHo48+Gj/96U/jwQcfbMN0yXaUv7a2Nm644Yb45je/GR06dEghWcvtaIZ169bFqaeeGqNHj47nnnsu7r777vjhD38YU6ZMSSHlju0of319fTz22GPRq1ev+PWvfx333Xdf/OhHP4of/OAHKaTcuaTnwYoVK+LJJ5+Mr371q22YquV2lH/z5s1x9NFHxw9+8INYvHhxPPDAA/Hd7343nn/++RRS7tiO8tfU1MTzzz8fzzzzTGzdujVefPHFmD17drz33nsppGyZ/348k6V9csT2j8eysk/+wM6OKUt9nxyx4/ylvj/+wH/PX0r7YyXaHnDggQfGpk2bmi374Pe0N/D+Zv369XH11VfHrFmz4pFHHonjjjsu7Ui7pH379nH44YfHuHHj4re//W0mzoR64IEHol27djF69Oi0o+yyQw89NKZNmxYjRoyIysrKOOqoo2LcuHHxm9/8JtavX592vEQfXFZx4403xkEHHRSHHnpofOUrX4nnnnsuNmzYkHK61pk3b168/fbbMWLEiLSjtMrPf/7zeOaZZ+LTn/50tGvXLrp37x5jx44tuUtGWqKysnKbLzZpaGiwX0vBH//4x7jkkkti69at8fDDD2eqWP5ARUVFVFRURM+ePeOzn/1sPPXUU2lHSlQsFuPaa6+N0aNHl/ylkDszYMCAePjhh+PUU0+NioqK6NWrV1x22WUxe/bstKO1SLt27aJnz54xYsSIqKioiOOPPz4+85nPxM9+9rO0o7XaT37yk6YvFciS7373u9GuXbs444wzoqKiIj72sY/F4MGDS/bLKf67Pn36xDe+8Y247777YsCAAfHQQw/F8OHDS+oytg/b3vFMlvbJ+8Lx2M5myMI+eWf5s7A//u/5e/ToUVL7YyXaHtC9e/dYu3ZtrF69umnZ8uXL44gjjoiOHTummGz/8sYbb8SFF14Y69evj0cffTRzL9gvvfRSfOITn2j2LX6bN2+OioqKTFwa+cQTT8T8+fOjX79+0a9fv3jqqafiqaeein79+qUdrcWWLFkS3/zmN5s+yyri/W2Qz+dL7nM/tqdbt25RKBRiy5YtTcs+uFznwzNlwTPPPBM1NTXbXH5R6t56661tvomzvLw8KioqUkq063r06BFLly5ttmzZsmUl9xk++7rnnnsuRo4cGf/rf/2veOihh6JTp05pR2qVqVOnxle+8pVmyzZv3pyJOd56662YP39+/Pu//3vTvm3lypXxf/7P/4kvfOELacdrsV/84hcxffr0Zss2b94c7du3TylR63Tt2nWb19UPf+5klsyZMyczn/H5YStXrmz23iIiW/u2tWvXRvfu3WPWrFkxb968uP/+++Ott94qiYPx/25HxzNZ2Sdn/XgsYuczZGGfvKP8Wdkfby9/qe2PlWh7wDHHHBN9+/aN22+/PdavXx8rVqyI+++/P3NnUGRZfX19XHbZZdGnT5946KGHMvdh/BERxx13XDQ0NMQ999wTmzdvjr/+9a9x1113xYgRIzJR4Dz99NPx0ksvxcKFC2PhwoVx/vnnx/nnnx8LFy5MO1qLVVVVxbRp02Ly5MmxdevWWLlyZdx9993xqU99KhPb4IwzzoguXbrEDTfcEBs2bIg1a9bEt7/97Tj33HNL8v+S7cyLL74Yp5xyStoxWu3MM8+Md955J77//e9HY2NjrFixIr73ve/FkCFD0o7WajU1NbF69eqYOnVqbNmyJebOnRuzZs2KCy+8MO1o+40//OEPMXbs2Pja174W1113XSY/cqFfv37xi1/8ImbPnh2FQiFefPHFePjhh+PSSy9NO1qio446Kl555ZWm/drChQvjqKOOiltuuSUeeOCBtOO1WLFYjDvuuCNeeOGFKBaLsWjRonj44Yfj4osvTjtai1x44YXx+uuvx6RJk6KxsTFee+21eOSRRzJXRtXV1cXy5cszuW8bOHBgzJ49O377299GsViM+fPnx5NPPpmZfdtf/vKXuOiii5o+H3D27Nnx7LPPxqc//em0ozWzs+OZLOyT94XjsZ3NkIV98s7yZ2F/vKP8pbY/Lr0tn1ETJ06Mf/u3f4uPf/zjkc/nY9iwYXHVVVelHWu/8dhjj8XKlSvjZz/7WTz99NPN1i1atCilVK3ToUOHmDx5ctx+++0xYMCA6NixYwwZMiTGjh2bdrT9xhFHHBEPPPBAfOtb34rvfe97ccABB8TgwYMz85loFRUV8cMf/jDuvPPOGDRoULz33nsxcODATH424Jtvvhn/8A//kHaMVuvWrVs88MADce+998bkyZOjY8eOccEFF2TyeVxdXR1TpkyJCRMmxMSJE6Nz585x0003xemnn552tP3G97///di6dWtMmDAhJkyY0LS8b9++MXny5BSTtdxJJ50UEydOjHvvvTduuumm+MhHPhI33nhjJr/EKKtqamria1/7Wtx6662xatWqOPTQQ+NLX/pSZkqorl27xiOPPBLf+MY34sEHH4z27dvHpZdemrmPj3jzzTcjIpp9EVlWjBw5MhoaGuK2226Ld955J4466qi49dZb45xzzkk7Wot89KMfjWuvvTauuuqqqKuri2OPPTa+//3vl9xZXEnHM6W+T94Xjsd2NsNpp51W8vvkpG1Q6vvjrDyGcsUsngsNAAAAAG3I5ZwAAAAAkECJBgAAAAAJlGgAAAAAkECJBgAAAAAJlGgAAAAAkECJBgAAAAAJlGgAAAAAkECJBgCQcW+++WYcd9xx8eabb+70dvPmzYvjjjtul/+e0aNHx3e/+91dvj8AQJYp0QAAAAAggRINAGAf8tJLL8VnP/vZOPPMM6Nnz54xfPjw+MMf/tDsNg8++GCcffbZcdZZZ8Xdd98dmzdvblr305/+NIYMGRJ9+/aN4cOHx/PPP9/GEwAAlCYlGgDAPuK9996LK6+8MgYNGhS/+c1vYt68efGP//iP8Y1vfKPZ7V5//fWYPXt2/PCHP4w5c+bEpEmTIiLiueeei1tuuSW+/vWvx/z58+NLX/pSfOlLX4qlS5emMQ4AQElRogEA7CMqKiriRz/6UXz605+OzZs3x1//+teoqqqKVatWNd0ml8vF17/+9ejQoUP8j//xP+Jzn/tcPPnkkxER8cgjj8Sll14ap5xySpSVlcU555wTAwcOjOnTp6c1EgBAyShPOwAAAHtGPp+PF154IT7/+c/Hxo0bo1u3blFeXh7FYrHpNgcffHAcfPDBTb8feeSRTSXbX//615g/f37853/+Z9P6xsbGOP3009tuCACAEqVEAwDYR9TW1sb48eNj+vTpcdJJJ0VExJQpU+JPf/pT023Wr18fGzdujAMPPDAiIlasWBEf+chHIiLiiCOOiGHDhsUVV1zRdPuVK1dG+/bt23AKAIDS5HJOAIB9xJIlSyKfzzeVXn/4wx/i4YcfbvbFAY2NjXHnnXfGxo0bY/ny5fHQQw/FJZdcEhERF110UTz88MPx8ssvR0TEK6+8EsOHD4+nnnqq7YcBACgxzkQDANhHnHHGGfHpT386Ro0aFYVCIY4++ugYPXp03HPPPbF69eqIiKiqqoqqqqo4++yzo0OHDnHJJZfEqFGjIiLiE5/4RGzcuDFuuOGGWLlyZVRVVcWYMWNi9OjRaY4FAFAScsUPf0gGAAAAALANl3MCAAAAQAIlGgAAAAAkUKIBAAAAQAIlGgAAAAAkUKIBAAAAQAIlGgAAAAAkUKIBAAAAQAIlGgAAAAAkUKIBAAAAQAIlGgAAAAAkUKIBAAAAQAIlGgAAAAAk+P8AhVK3SFT3pJ0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.countplot(x=test_df['label'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58694c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_val = np.array(labels)\n",
    "np.unique(unique_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de656fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('label',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2363c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images =  train_df.values\n",
    "images = np.array([np.reshape(i,(28,28)) for i in images])\n",
    "images = np.array([i.flatten() for i in images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccec0ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "labels = label_binarizer.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acd61ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2307f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.grid\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08958942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eabc9b0ee0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 1\n",
    "print(labels[index])\n",
    "plt.imshow(images[index].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14ba35cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from opencv-python) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaa47c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use openCV to view 10 random images from our training data\n",
    "\n",
    "import cv2\n",
    "for i in range(0,10):\n",
    "    rand = np.random.randint(0,len(images))\n",
    "    input_im =  images[rand]\n",
    "    \n",
    "    sample = input_im.reshape(28,28).astype(np.uint8)\n",
    "    sample = cv2.resize(sample, None, fx=10, fy=10, interpolation = cv2.INTER_CUBIC)\n",
    "    cv2.imshow(\"Sample Image\",sample)\n",
    "    cv2.waitKey()\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf0e5bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into X_train, X_test, y_train and y_test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images,labels,test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce5216a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.25.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.59.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (22.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ladhani\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c9ba9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Loading our tensorflow modules and define our batch size etc\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "025edad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =128\n",
    "num_classes = 24\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a8b64fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale our images\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc66bcb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eaec64d3f0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Reshape them into the size required by TF and Keras\n",
    "X_train = X_train.reshape(X_train.shape[0],28,28,1)\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1)\n",
    "\n",
    "plt.imshow(X_train[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02ca88b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our CNN Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation = 'relu', input_shape=(28, 28,1))) \n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu')) \n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense (128, activation = 'relu'))\n",
    "model.add(Dropout (0.20))\n",
    "\n",
    "model.add(Dense (num_classes, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84957a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile Model\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = Adam(), metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b4230b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 1, 1, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85912 (335.59 KB)\n",
      "Trainable params: 85912 (335.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "708d7f40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "151/151 [==============================] - 15s 88ms/step - loss: 2.5644 - accuracy: 0.2101 - val_loss: 1.5869 - val_accuracy: 0.5296\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 13s 87ms/step - loss: 1.1749 - accuracy: 0.6080 - val_loss: 0.7057 - val_accuracy: 0.7771\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 13s 87ms/step - loss: 0.6612 - accuracy: 0.7754 - val_loss: 0.4637 - val_accuracy: 0.8532\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 13s 85ms/step - loss: 0.4421 - accuracy: 0.8500 - val_loss: 0.3079 - val_accuracy: 0.9037\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 13s 86ms/step - loss: 0.3063 - accuracy: 0.8964 - val_loss: 0.1737 - val_accuracy: 0.9528\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 13s 86ms/step - loss: 0.2037 - accuracy: 0.9325 - val_loss: 0.0996 - val_accuracy: 0.9750\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 13s 85ms/step - loss: 0.1533 - accuracy: 0.9487 - val_loss: 0.0701 - val_accuracy: 0.9869\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 13s 86ms/step - loss: 0.1056 - accuracy: 0.9688 - val_loss: 0.0534 - val_accuracy: 0.9907\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 13s 86ms/step - loss: 0.0872 - accuracy: 0.9729 - val_loss: 0.0359 - val_accuracy: 0.9937\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 13s 85ms/step - loss: 0.0600 - accuracy: 0.9829 - val_loss: 0.0281 - val_accuracy: 0.9956\n"
     ]
    }
   ],
   "source": [
    "#Train model\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data= (X_test,y_test), epochs=epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "127efca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ladhani\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"sign_mnist_cnn_10_epochs.h5\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7147277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View our training history graphically \n",
    "\n",
    "plt.plot(history.history['accuracy']) \n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40116f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 2s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Reshape our test data so that we can evaluate it's performance on unseen data \n",
    "test_labels = test_df['label']\n",
    "test_df.drop('label', axis= 1, inplace=True)\n",
    "test_images = test_df.values\n",
    "test_images = np.array([np.reshape(i, (28,28)) for i in test_images])\n",
    "test_images = np.array([i.flatten() for i in test_images])\n",
    "\n",
    "test_labels = label_binarizer.fit_transform(test_labels)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "test_images.shape\n",
    "y_pred = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "56184bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8135805911879531"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get our accuracy score I\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_labels, y_pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ece35e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to match label to letter \n",
    "def getLetter(result):\n",
    "    classLabels = { 0: 'A',\n",
    "                    1: 'B',\n",
    "                    2: 'C',\n",
    "                    3: 'D',\n",
    "                    4: 'E',\n",
    "                    5: 'F',\n",
    "                    6: 'G',\n",
    "                    7: 'H',\n",
    "                    8: 'I',\n",
    "                    9: 'K',\n",
    "                    10: 'L',\n",
    "                    11: 'M',\n",
    "                    12: 'N',\n",
    "                    13: '0',\n",
    "                    14: 'P',\n",
    "                    15: 'Q',\n",
    "                    16: 'R',\n",
    "                    17: 'S',\n",
    "                    18: 'T',\n",
    "                    19: 'U',\n",
    "                    20: 'V',\n",
    "                    21: 'W',\n",
    "                    22: 'X',\n",
    "                    23: 'Y'}\n",
    "    try:\n",
    "        res =  int(result)\n",
    "        return classLabels[res]\n",
    "    except:\n",
    "        return \"Error\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca07c890",
   "metadata": {},
   "source": [
    "## Test on Actual Webcam Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1d535ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model('sign_mnist_cnn_10_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1dc40d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap= cv2.VideoCapture (0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    ##############################\n",
    "    frame=cv2.flip(frame, 1)\n",
    "    #define region of interest \n",
    "    roi = frame[100:400, 320:620]\n",
    "    cv2.imshow('roi', roi)\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    roi = cv2.resize(roi, (28, 28), interpolation = cv2.INTER_AREA)\n",
    "    cv2.imshow('roi scaled and gray', roi)\n",
    "    copy = frame.copy()\n",
    "    cv2.rectangle(copy, (320, 100), (620, 400), (255,0,0), 5)\n",
    "    roi = roi.reshape(1,28,28,1)\n",
    "    result = model.predict(roi)\n",
    "    predicted_class = np.argmax(result)\n",
    "#     result = str(model.predict_classes(roi, 1, verbose = 0)[0])\n",
    "#     cv2.putText(copy, getLetter (result), (300, 100), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 255, 0), 2) \n",
    "    cv2.putText(copy, getLetter(predicted_class), (300, 100), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('frame', copy)\n",
    "    \n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856ebcad",
   "metadata": {},
   "source": [
    "Performance is very low. Not able to any alphabet.\n",
    "So now going to use large dataset which have more alphabet images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf3b6dc",
   "metadata": {},
   "source": [
    "## let's Use Keras's Data Augmentation to enhance our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ba13874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras. preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca29b82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 32\n",
    "image_size = 200\n",
    "img_channel = 3\n",
    "n_classes = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "848774dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r'C:\\Users\\Ladhani\\Desktop\\Ai & ml 2\\CapstoneProject\\code\\ASL_Dataset\\train'\n",
    "val_path = r'C:\\Users\\Ladhani\\Desktop\\Ai & ml 2\\CapstoneProject\\code\\ASL_Dataset\\val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "674420c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale= 1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d14c7a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2012 images belonging to 36 classes.\n",
      "Found 503 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = datagen.flow_from_directory(directory= train_path, \n",
    "                                         target_size=(image_size,image_size), \n",
    "                                         batch_size = batch, \n",
    "                                         class_mode='categorical')\n",
    "\n",
    "val_data = datagen.flow_from_directory(directory= val_path, \n",
    "                                       target_size=(image_size,image_size), \n",
    "                                       batch_size = batch, \n",
    "                                       class_mode='categorical',\n",
    "                                       shuffle= False\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c1338b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 200, 200, 32)      896       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 200, 200, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 100, 100, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100, 100, 32)      0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 100, 100, 64)      18496     \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 100, 100, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 50, 50, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50, 50, 64)        0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 50, 50, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 25, 25, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 25, 25, 128)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 80000)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               40960512  \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 36)                4644      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41317828 (157.62 MB)\n",
      "Trainable params: 41317828 (157.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# input layer\n",
    "# Block 1\n",
    "model.add(Conv2D(32,3,activation='relu',padding='same',input_shape = (image_size,image_size,img_channel)))\n",
    "model.add(Conv2D(32,3,activation='relu',padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block 2\n",
    "model.add(Conv2D(64,3,activation='relu',padding='same'))\n",
    "model.add(Conv2D(64,3,activation='relu',padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(padding='same'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#Block 3\n",
    "model.add(Conv2D(128,3,activation='relu',padding='same'))\n",
    "model.add(Conv2D(128,3,activation='relu',padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(padding='same'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# fully connected layer\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(36, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "108b6d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "early_stoping = EarlyStopping(monitor='val_loss', \n",
    "                              min_delta=0.001,\n",
    "                              patience= 5,\n",
    "                              restore_best_weights= True, \n",
    "                              verbose = 0)\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                         patience = 2, \n",
    "                                         factor=0.5 , \n",
    "                                         verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f0ac32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "faf363b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "63/63 [==============================] - 234s 4s/step - loss: 2.4564 - accuracy: 0.3176 - val_loss: 0.7263 - val_accuracy: 0.8052 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 235s 4s/step - loss: 0.6694 - accuracy: 0.7898 - val_loss: 0.3274 - val_accuracy: 0.8986 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 231s 4s/step - loss: 0.3183 - accuracy: 0.8971 - val_loss: 0.2673 - val_accuracy: 0.9145 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 234s 4s/step - loss: 0.2256 - accuracy: 0.9269 - val_loss: 0.2874 - val_accuracy: 0.9085 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 228s 4s/step - loss: 0.1462 - accuracy: 0.9493 - val_loss: 0.2431 - val_accuracy: 0.9344 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 231s 4s/step - loss: 0.1045 - accuracy: 0.9662 - val_loss: 0.1954 - val_accuracy: 0.9404 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 192s 3s/step - loss: 0.1017 - accuracy: 0.9667 - val_loss: 0.1934 - val_accuracy: 0.9523 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 204s 3s/step - loss: 0.0928 - accuracy: 0.9742 - val_loss: 0.1725 - val_accuracy: 0.9463 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9727\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "63/63 [==============================] - 197s 3s/step - loss: 0.0745 - accuracy: 0.9727 - val_loss: 0.2060 - val_accuracy: 0.9523 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 206s 3s/step - loss: 0.0349 - accuracy: 0.9876 - val_loss: 0.1945 - val_accuracy: 0.9642 - lr: 5.0000e-04\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 200s 3s/step - loss: 0.0306 - accuracy: 0.9901 - val_loss: 0.2120 - val_accuracy: 0.9642 - lr: 5.0000e-04\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - 198s 3s/step - loss: 0.0299 - accuracy: 0.9925 - val_loss: 0.1694 - val_accuracy: 0.9682 - lr: 5.0000e-04\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 197s 3s/step - loss: 0.0229 - accuracy: 0.9935 - val_loss: 0.1992 - val_accuracy: 0.9662 - lr: 5.0000e-04\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9945\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "63/63 [==============================] - 194s 3s/step - loss: 0.0188 - accuracy: 0.9945 - val_loss: 0.2258 - val_accuracy: 0.9682 - lr: 5.0000e-04\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - 195s 3s/step - loss: 0.0146 - accuracy: 0.9965 - val_loss: 0.2097 - val_accuracy: 0.9702 - lr: 2.5000e-04\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 196s 3s/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.2291 - val_accuracy: 0.9682 - lr: 2.5000e-04\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9965\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "63/63 [==============================] - 195s 3s/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.2284 - val_accuracy: 0.9662 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "asl_class = model.fit(train_data, \n",
    "                      validation_data= val_data, \n",
    "                      epochs=30, \n",
    "                      callbacks=[early_stoping,reduce_learning_rate],\n",
    "                      verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43653e0",
   "metadata": {},
   "source": [
    "## Now let's test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "423c72d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model for training data is: 99.85089302062988\n",
      "The Loss of the model for training data is: 0.0029748897068202496\n",
      "The accuracy of the model for validation data is: 96.8190848827362\n",
      "The Loss of the model for validation data is: 0.16937659680843353\n"
     ]
    }
   ],
   "source": [
    "# Evaluvate for train generator\n",
    "loss,acc = model.evaluate(train_data , verbose = 0)\n",
    "\n",
    "print('The accuracy of the model for training data is:',acc*100)\n",
    "print('The Loss of the model for training data is:',loss)\n",
    "\n",
    "# Evaluvate for validation generator\n",
    "loss,acc = model.evaluate(val_data, verbose = 0)\n",
    "\n",
    "print('The accuracy of the model for validation data is:',acc*100)\n",
    "print('The Loss of the model for validation data is:',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41b1b5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ladhani\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights saved\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"sign_asl_cnn_30_epochs.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "print('Model Saved')\n",
    "model.save('sign_asl_cnn_30_epochs.h5')\n",
    "model.save_weights('model-sign_asl_cnn_30_epochs_weight.h5')\n",
    "print('Weights saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eb3bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "classifier = load_model('sign_asl_cnn_30_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c96bf2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 67ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 350ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 108ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 364ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 379ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Prediction [[0.04630103 0.02148617 0.02528005 0.02007238 0.02642707 0.02246412\n",
      "  0.03485465 0.01948171 0.02070639 0.01941021 0.01793249 0.02917457\n",
      "  0.02999326 0.03534606 0.01885636 0.01249114 0.02907845 0.02255209\n",
      "  0.04104931 0.0345776  0.01329998 0.02421369 0.04094679 0.03408658\n",
      "  0.03099541 0.02301072 0.04138171 0.01415333 0.02377733 0.01791476\n",
      "  0.04277235 0.03204399 0.02284271 0.03281493 0.04245496 0.03575566]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import skimage as ski\n",
    "from skimage import filters\n",
    "\n",
    "\n",
    "# Load a pre-trained classifier or model for making predictions\n",
    "# Replace 'classifier' with your actual model or classifier\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "def classes(result):\n",
    "    class_labels = {i: str(i) if i < 10 else chr(65 + i - 10) for i in range(36)}\n",
    "    return class_labels[result]\n",
    "\n",
    "# class_labels = {0:'0', 1:'1',2:'2',3:'3',4:'4',5:'5',6:'6',7:'7',8:'8',9:'9',10:'A',11:'B',12:'C',13:'D',\n",
    "#                14:'E',15:'F',16:'G',17:'H',18:'I',19:'J',20:'K',21:'L',22:'M',23:'N',24:'O',25:'P',26:'Q',27:'R',\n",
    "#                28:'S',29:'T',30:'U',31:'V',32:'W',33:'X',34:'Y',35:'Z'}\n",
    "while True:\n",
    "    \n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Flip the frame horizontally\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    '''# Define the ROI\n",
    "    roi = frame[100:300, 320:520]\n",
    "\n",
    "    # Blur the ROI\n",
    "    blurred_roi = cv2.GaussianBlur(roi, (15, 15), 0)\n",
    "\n",
    "    # Replace the ROI in the frame with the blurred ROI\n",
    "    frame[100:300, 320:520] = blurred_roi\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Blurred Frame', frame)'''\n",
    "    \n",
    "    # Create a black ROI\n",
    "    roi_width = 200\n",
    "    roi_height = 200\n",
    "    black_roi = np.zeros((roi_height, roi_width, 3), np.uint8)\n",
    "\n",
    "    # Replace the ROI in the original frame with the black ROI\n",
    "    frame[100:300, 320:520] = black_roi\n",
    "\n",
    "    # Display the modified frame\n",
    "    cv2.imshow('black', frame)\n",
    "\n",
    "\n",
    "    # Define region of interest\n",
    "    roi = frame[100:300, 320:520]  # Adjust the ROI dimensions (200x200)\n",
    "    cv2.imshow('roi', roi)\n",
    "    \n",
    "    \n",
    "    # Convert ROI to grayscale\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Resize ROI to (200, 200) and convert it to 3 channels\n",
    "    roi = cv2.resize(roi, (200, 200), interpolation=cv2.INTER_AREA)\n",
    "    roi = cv2.cvtColor(roi, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Scale the pixel values to the range [0, 1]\n",
    "    roi = roi / 255.0\n",
    "    \n",
    "    cv2.imshow('roi scaled and color', roi)\n",
    "    \n",
    "    copy = frame.copy()\n",
    "    \n",
    "    cv2.rectangle(copy, (320, 100), (520, 300), (255, 0, 0), 5)\n",
    "   \n",
    "    # Reshape ROI for prediction\n",
    "    roi = roi.reshape(1, 200, 200, 3)  # Ensure it matches your model's input shape\n",
    "    \n",
    "    predictions = classifier.predict(roi)\n",
    "    print(\"Prediction\", predictions)\n",
    "    \n",
    "    predicted_class = int(np.argmax(predictions, axis=1)[0])\n",
    "    \n",
    "    result = classes(predicted_class)\n",
    "   \n",
    "    cv2.putText(copy, str(result), (300, 100), cv2.FONT_HERSHEY_COMPLEX, 2, (0, 255, 0), 2)\n",
    "    cv2.imshow('frame', copy)\n",
    "\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbfc53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d7fa03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
